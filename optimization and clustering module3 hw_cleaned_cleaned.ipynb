{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvXL2kp4ZvLm"
   },
   "source": [
    "🎨 Color Semantic Dashboard\n",
    "This interactive dashboard enables exploration and analysis of colors based on semantic associations and RGB clustering. It is designed for applications in creative consulting, branding, narrative psychology, and color metaphors as used in La Matrice Consulting.\n",
    "\n",
    "📊 What This Tool Does\n",
    "🧠 Semantic Matching: Associates color names with emotionally descriptive words from surveys and datasets.\n",
    "\n",
    "🔍 Clustering: Groups 216+ unique colors into 5 semantic clusters using:\n",
    "\n",
    "K-Means Clustering with sentiment-enhanced RGB features.\n",
    "\n",
    "Cosine similarity to define weights between semantic centers.\n",
    "\n",
    "🎯 Filtering & Search:\n",
    "\n",
    "Filter by RGB ranges using sliders.\n",
    "\n",
    "Choose preset filters (Warm, Cool, Red-dominant, etc.).\n",
    "\n",
    "Enter a word (e.g., \"hope\", \"fierce\", \"balance\") to find related colors.\n",
    "\n",
    "🌐 Visualizations:\n",
    "\n",
    "3D RGB scatterplot of color clusters.\n",
    "\n",
    "Swatch displays by sentiment themes.\n",
    "\n",
    "Recommended palettes combining word association and cluster diversity.\n",
    "\n",
    "🧮 Underlying Techniques\n",
    "Color Data: Parsed from CSVs including RGB values, color names, and semantic keywords.\n",
    "\n",
    "Sentiment Feature Extraction: Text vectorization via CountVectorizer transforms words into binary sentiment features.\n",
    "\n",
    "Clustering:\n",
    "\n",
    "X\n",
    "=\n",
    "[R, G, B]\n",
    "+\n",
    "sentiment vector\n",
    "X=[R, G, B]+sentiment vector\n",
    "𝑘\n",
    "-means:\n",
    "min\n",
    "⁡\n",
    "∑\n",
    "𝑖\n",
    "=\n",
    "1\n",
    "𝑘\n",
    "∑\n",
    "𝑥\n",
    "∈\n",
    "𝐶\n",
    "𝑖\n",
    "∥\n",
    "𝑥\n",
    "−\n",
    "𝜇\n",
    "𝑖\n",
    "∥\n",
    "2\n",
    "k-means: min\n",
    "i=1\n",
    "∑\n",
    "k\n",
    "​\n",
    "  \n",
    "x∈C\n",
    "i\n",
    "​\n",
    "\n",
    "∑\n",
    "​\n",
    " ∥x−μ\n",
    "i\n",
    "​\n",
    " ∥\n",
    "2\n",
    "\n",
    "Similarity Scoring: Overlap and prefix matching to find closely related words in meaning or structure.\n",
    "\n",
    "Color Matching: Finds closest color in RGB space by computing:\n",
    "\n",
    "𝑑\n",
    "=\n",
    "(\n",
    "𝑅\n",
    "1\n",
    "−\n",
    "𝑅\n",
    "2\n",
    ")\n",
    "2\n",
    "+\n",
    "(\n",
    "𝐺\n",
    "1\n",
    "−\n",
    "𝐺\n",
    "2\n",
    ")\n",
    "2\n",
    "+\n",
    "(\n",
    "𝐵\n",
    "1\n",
    "−\n",
    "𝐵\n",
    "2\n",
    ")\n",
    "2\n",
    "d=\n",
    "(R\n",
    "1\n",
    "​\n",
    " −R\n",
    "2\n",
    "​\n",
    " )\n",
    "2\n",
    " +(G\n",
    "1\n",
    "​\n",
    " −G\n",
    "2\n",
    "​\n",
    " )\n",
    "2\n",
    " +(B\n",
    "1\n",
    "​\n",
    " −B\n",
    "2\n",
    "​\n",
    " )\n",
    "2\n",
    "\n",
    "​\n",
    "\n",
    "🧰 Technologies Used\n",
    "pandas & NumPy for data manipulation\n",
    "\n",
    "matplotlib & mpl_toolkits for RGB and swatch visualizations\n",
    "\n",
    "scikit-learn for clustering & feature extraction\n",
    "\n",
    "ipywidgets for a fully interactive experience\n",
    "\n",
    "colormath for color space conversions (LAB, Delta-E)\n",
    "\n",
    "💡 Why Use This?\n",
    "Use this tool to:\n",
    "\n",
    "Understand emotional and semantic associations behind your color choices.\n",
    "\n",
    "Generate meaningful palettes for brand identity or storytelling.\n",
    "\n",
    "Explore how color perception and emotion cluster across psychological data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_L5F0qDUckcp"
   },
   "outputs": [],
   "source": [
    "\n",
    "import nbformat\n",
    "from google.colab import _message\n",
    "\n",
    "# Step 1: Get the current notebook as a dict\n",
    "current_notebook = _message.blocking_request('get_ipynb')['ipynb']\n",
    "\n",
    "# Step 2: Convert it to a proper NotebookNode\n",
    "nb_node = nbformat.from_dict(current_notebook)\n",
    "\n",
    "# Step 3: Remove broken widgets metadata if it exists\n",
    "if 'widgets' in nb_node['metadata']:\n",
    "    del nb_node['metadata']['widgets']\n",
    "\n",
    "# Step 4: Save the cleaned notebook\n",
    "cleaned_path = '/content/cleaned_notebook.ipynb'\n",
    "with open(cleaned_path, 'w') as f:\n",
    "    nbformat.write(nb_node, f)\n",
    "\n",
    "print(f\"✅ Cleaned notebook saved to {cleaned_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1686,
     "status": "ok",
     "timestamp": 1745773502918,
     "user": {
      "displayName": "Danielle Gauthier",
      "userId": "15668431405707832125"
     },
     "user_tz": 240
    },
    "id": "pGgYj-eiM0yh",
    "outputId": "851fe96c-2f4a-42f1-941e-c90aefaa81df"
   },
   "outputs": [],
   "source": [
    "import nbformat\n",
    "from google.colab import _message\n",
    "\n",
    "# Step 1: Get the current notebook as a dict\n",
    "current_notebook = _message.blocking_request('get_ipynb')['ipynb']\n",
    "\n",
    "# Step 2: Convert it to a proper NotebookNode\n",
    "nb_node = nbformat.from_dict(current_notebook)\n",
    "\n",
    "# Step 3: Remove broken widgets metadata if it exists\n",
    "if 'widgets' in nb_node['metadata']:\n",
    "    del nb_node['metadata']['widgets']\n",
    "\n",
    "# Step 4: Save the cleaned notebook\n",
    "cleaned_path = '/content/cleaned_notebook.ipynb'\n",
    "with open(cleaned_path, 'w') as f:\n",
    "    nbformat.write(nb_node, f)\n",
    "\n",
    "print(f\"✅ Cleaned notebook saved to {cleaned_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_ThWp2seSzK"
   },
   "source": [
    "# Color clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c78CiQaiRPbd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11710,
     "status": "ok",
     "timestamp": 1744679658531,
     "user": {
      "displayName": "Danielle Gauthier",
      "userId": "15668431405707832125"
     },
     "user_tz": 240
    },
    "id": "LK7HiGq8AlHV",
    "outputId": "a76cde72-69cc-4ecf-e2d2-cf765dbc67f1"
   },
   "outputs": [],
   "source": [
    "!pip install requests pandas numpy scikit-learn matplotlib requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4724,
     "status": "ok",
     "timestamp": 1744680600477,
     "user": {
      "displayName": "Danielle Gauthier",
      "userId": "15668431405707832125"
     },
     "user_tz": 240
    },
    "id": "T2YIQDrfAb4A",
    "outputId": "8b9984fb-ff54-4d59-ffb6-67355b1f0c6f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import requests\n",
    "from io import StringIO\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import silhouette_score\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# URLs for the CSV files\n",
    "colors_url = \"https://hebbkx1anhila5yf.public.blob.vercel-storage.com/la%20matrice-qhiF8W1MZiXnmjlkL6xJasXeG1FryC.csv\"\n",
    "sequences_url = \"https://hebbkx1anhila5yf.public.blob.vercel-storage.com/la%20matrice%20sequences-2j9pbWxr7vXA22q5VUTWXYgyaSe9dO.csv\"\n",
    "\n",
    "# Function to fetch and parse CSV data\n",
    "def fetch_csv(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return pd.read_csv(StringIO(response.text))\n",
    "    else:\n",
    "        raise Exception(f\"Failed to fetch data: {response.status_code}\")\n",
    "\n",
    "# Fetch the data\n",
    "print(\"Fetching color data...\")\n",
    "colors_df = fetch_csv(colors_url)\n",
    "print(\"Fetching sequence data...\")\n",
    "sequences_df = fetch_csv(sequences_url)\n",
    "\n",
    "# Display the first few rows of each dataset\n",
    "print(\"\\nColor Data Sample:\")\n",
    "print(colors_df.head())\n",
    "print(\"\\nSequence Data Sample:\")\n",
    "print(sequences_df.head())\n",
    "\n",
    "# Clean and prepare the color sentiment data\n",
    "print(\"\\nPreparing color sentiment data...\")\n",
    "\n",
    "# Make sure RGB values are numeric\n",
    "for col in ['r', 'g', 'b']:\n",
    "    colors_df[col] = pd.to_numeric(colors_df[col], errors='coerce')\n",
    "\n",
    "# Extract sentiment features using text vectorization\n",
    "# First, clean the english-words column\n",
    "colors_df['clean_words'] = colors_df['english-words'].fillna('').astype(str)\n",
    "\n",
    "# Use CountVectorizer to create binary features for sentiment words\n",
    "vectorizer = CountVectorizer(binary=True, max_features=100)\n",
    "sentiment_features = vectorizer.fit_transform(colors_df['clean_words'])\n",
    "sentiment_df = pd.DataFrame(\n",
    "    sentiment_features.toarray(),\n",
    "    columns=[f'sentiment_{word}' for word in vectorizer.get_feature_names_out()],\n",
    "    index=colors_df.index\n",
    ")\n",
    "\n",
    "# Combine RGB values with sentiment features\n",
    "X_rgb = colors_df[['r', 'g', 'b']].fillna(0)\n",
    "X = pd.concat([X_rgb, sentiment_df], axis=1)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Determine optimal number of clusters using the elbow method\n",
    "inertia = []\n",
    "k_range = range(2, 10)\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the elbow curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, inertia, 'o-')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.grid(True)\n",
    "print(\"Determining optimal number of clusters...\")\n",
    "\n",
    "# Calculate silhouette scores\n",
    "silhouette_scores = []\n",
    "for k in range(2, 10):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(X_scaled)\n",
    "    silhouette_avg = silhouette_score(X_scaled, cluster_labels)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "\n",
    "# Plot silhouette scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(2, 10), silhouette_scores, 'o-')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Analysis for Optimal k')\n",
    "plt.grid(True)\n",
    "\n",
    "# Choose k=5 based on analysis\n",
    "k = 5\n",
    "print(f\"\\nPerforming k-means clustering with k={k}...\")\n",
    "kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "colors_df['cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Visualize the clusters using PCA for dimensionality reduction\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for cluster in range(k):\n",
    "    plt.scatter(\n",
    "        X_pca[colors_df['cluster'] == cluster, 0],\n",
    "        X_pca[colors_df['cluster'] == cluster, 1],\n",
    "        label=f'Cluster {cluster}',\n",
    "        alpha=0.7\n",
    "    )\n",
    "plt.title('Color Sentiment Clusters (PCA)')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Analyze the clusters\n",
    "print(\"\\nCluster Analysis:\")\n",
    "for cluster in range(k):\n",
    "    cluster_colors = colors_df[colors_df['cluster'] == cluster]\n",
    "    print(f\"\\nCluster {cluster} ({len(cluster_colors)} colors):\")\n",
    "    print(f\"  Common colors: {', '.join(cluster_colors['color'].value_counts().head(5).index.tolist())}\")\n",
    "\n",
    "    # Find most common sentiment words in this cluster\n",
    "    cluster_sentiments = sentiment_df.loc[cluster_colors.index].sum().sort_values(ascending=False)\n",
    "    print(f\"  Top sentiments: {', '.join(cluster_sentiments.head(5).index.str.replace('sentiment_', '').tolist())}\")\n",
    "\n",
    "    # Average RGB values for this cluster\n",
    "    avg_rgb = cluster_colors[['r', 'g', 'b']].mean()\n",
    "    print(f\"  Average RGB: ({avg_rgb['r']:.1f}, {avg_rgb['g']:.1f}, {avg_rgb['b']:.1f})\")\n",
    "\n",
    "# Create a color-to-cluster mapping\n",
    "color_to_cluster = dict(zip(colors_df['color'], colors_df['cluster']))\n",
    "\n",
    "# Parse the sequences\n",
    "print(\"\\nAnalyzing color sequences...\")\n",
    "def parse_sequence(seq_str):\n",
    "    if pd.isna(seq_str):\n",
    "        return []\n",
    "    return [color.strip().lower() for color in seq_str.split(',')]\n",
    "\n",
    "sequences_df['parsed_sequence'] = sequences_df['sequence'].apply(parse_sequence)\n",
    "\n",
    "# Calculate sequence momentum based on cluster transitions\n",
    "def calculate_momentum(sequence, color_to_cluster, cluster_weights=None):\n",
    "    if cluster_weights is None:\n",
    "        # Default weights: transitions between different clusters have higher momentum\n",
    "        cluster_weights = np.ones((k, k)) - np.eye(k)\n",
    "\n",
    "    momentum = 0\n",
    "    valid_transitions = 0\n",
    "\n",
    "    for i in range(len(sequence) - 1):\n",
    "        color1 = sequence[i]\n",
    "        color2 = sequence[i + 1]\n",
    "\n",
    "        # Skip if colors not in our dataset\n",
    "        if color1 not in color_to_cluster or color2 not in color_to_cluster:\n",
    "            continue\n",
    "\n",
    "        cluster1 = color_to_cluster[color1]\n",
    "        cluster2 = color_to_cluster[color2]\n",
    "\n",
    "        # Add momentum based on cluster transition\n",
    "        momentum += cluster_weights[cluster1, cluster2]\n",
    "        valid_transitions += 1\n",
    "\n",
    "    # Return average momentum per transition to normalize for sequence length\n",
    "    return momentum / max(1, valid_transitions)\n",
    "\n",
    "# Define cluster transition weights based on sentiment similarity\n",
    "# Calculate sentiment similarity between clusters\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "# Extract just the sentiment part of the cluster centers (not RGB)\n",
    "sentiment_centers = cluster_centers[:, 3:]\n",
    "# Calculate cosine similarity between sentiment centers\n",
    "sentiment_similarity = np.zeros((k, k))\n",
    "for i in range(k):\n",
    "    for j in range(k):\n",
    "        # Dot product of normalized vectors = cosine similarity\n",
    "        norm_i = np.linalg.norm(sentiment_centers[i])\n",
    "        norm_j = np.linalg.norm(sentiment_centers[j])\n",
    "        if norm_i > 0 and norm_j > 0:\n",
    "            sentiment_similarity[i, j] = np.dot(sentiment_centers[i], sentiment_centers[j]) / (norm_i * norm_j)\n",
    "        else:\n",
    "            sentiment_similarity[i, j] = 0\n",
    "\n",
    "# Convert similarity to weights (higher similarity = lower momentum)\n",
    "cluster_weights = 1 - sentiment_similarity\n",
    "\n",
    "# Visualize the cluster transition weights as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(cluster_weights, cmap='viridis', interpolation='nearest')\n",
    "plt.colorbar(label='Momentum Weight')\n",
    "plt.title('Cluster Transition Momentum Weights')\n",
    "plt.xlabel('To Cluster')\n",
    "plt.ylabel('From Cluster')\n",
    "for i in range(k):\n",
    "    for j in range(k):\n",
    "        plt.text(j, i, f'{cluster_weights[i, j]:.2f}',\n",
    "                 ha='center', va='center',\n",
    "                 color='white' if cluster_weights[i, j] > 0.5 else 'black')\n",
    "plt.xticks(range(k))\n",
    "plt.yticks(range(k))\n",
    "\n",
    "# Calculate momentum for each sequence\n",
    "sequences_df['momentum'] = sequences_df['parsed_sequence'].apply(\n",
    "    lambda seq: calculate_momentum(seq, color_to_cluster, cluster_weights)\n",
    ")\n",
    "\n",
    "# Find sequences with highest and lowest momentum\n",
    "print(\"\\nSequences with Highest Momentum:\")\n",
    "high_momentum = sequences_df.sort_values('momentum', ascending=False).head(5)\n",
    "for _, row in high_momentum.iterrows():\n",
    "    print(f\"  {row['ï»¿name']}: {row['sequence']} (Momentum: {row['momentum']:.2f})\")\n",
    "\n",
    "print(\"\\nSequences with Lowest Momentum:\")\n",
    "low_momentum = sequences_df.sort_values('momentum').head(5)\n",
    "for _, row in low_momentum.iterrows():\n",
    "    print(f\"  {row['ï»¿name']}: {row['sequence']} (Momentum: {row['momentum']:.2f})\")\n",
    "\n",
    "# Function to optimize a sequence by maximizing or minimizing momentum\n",
    "def optimize_sequence(sequence, color_to_cluster, cluster_weights, maximize=True, iterations=100):\n",
    "    colors_in_clusters = {}\n",
    "    for color, cluster in color_to_cluster.items():\n",
    "        if cluster not in colors_in_clusters:\n",
    "            colors_in_clusters[cluster] = []\n",
    "        colors_in_clusters[cluster].append(color)\n",
    "\n",
    "    best_sequence = sequence.copy()\n",
    "    best_momentum = calculate_momentum(best_sequence, color_to_cluster, cluster_weights)\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        # Randomly select a position to modify\n",
    "        if len(sequence) == 0:\n",
    "            continue\n",
    "        pos = np.random.randint(0, len(sequence))\n",
    "\n",
    "        # Get current color and its cluster\n",
    "        if sequence[pos] not in color_to_cluster:\n",
    "            continue\n",
    "        current_cluster = color_to_cluster[sequence[pos]]\n",
    "\n",
    "        # Choose a random different cluster and a random color from it\n",
    "        other_clusters = [c for c in range(k) if c != current_cluster and c in colors_in_clusters]\n",
    "        if not other_clusters:\n",
    "            continue\n",
    "        new_cluster = np.random.choice(other_clusters)\n",
    "        new_color = np.random.choice(colors_in_clusters[new_cluster])\n",
    "\n",
    "        # Create a new sequence with the modified color\n",
    "        new_sequence = sequence.copy()\n",
    "        new_sequence[pos] = new_color\n",
    "\n",
    "        # Calculate new momentum\n",
    "        new_momentum = calculate_momentum(new_sequence, color_to_cluster, cluster_weights)\n",
    "\n",
    "        # Update if better (higher momentum if maximizing, lower if minimizing)\n",
    "        if (maximize and new_momentum > best_momentum) or (not maximize and new_momentum < best_momentum):\n",
    "            best_sequence = new_sequence\n",
    "            best_momentum = new_momentum\n",
    "\n",
    "    return best_sequence, best_momentum\n",
    "\n",
    "# Example: Optimize a sequence to maximize momentum\n",
    "print(\"\\nOptimizing Sequences:\")\n",
    "sample_sequence = sequences_df.iloc[0]['parsed_sequence']\n",
    "if len(sample_sequence) > 0:\n",
    "    print(f\"Original sequence: {', '.join(sample_sequence)}\")\n",
    "\n",
    "    # Maximize momentum\n",
    "    optimized_max, max_momentum = optimize_sequence(\n",
    "        sample_sequence, color_to_cluster, cluster_weights, maximize=True\n",
    "    )\n",
    "    print(f\"Optimized for maximum momentum: {', '.join(optimized_max)} (Momentum: {max_momentum:.2f})\")\n",
    "\n",
    "    # Minimize momentum\n",
    "    optimized_min, min_momentum = optimize_sequence(\n",
    "        sample_sequence, color_to_cluster, cluster_weights, maximize=False\n",
    "    )\n",
    "    print(f\"Optimized for minimum momentum: {', '.join(optimized_min)} (Momentum: {min_momentum:.2f})\")\n",
    "\n",
    "# Create a function to generate new sequences based on sentiment clusters\n",
    "def generate_sequence_from_clusters(length, color_to_cluster, colors_in_clusters, target_clusters=None):\n",
    "    if target_clusters is None:\n",
    "        target_clusters = list(range(k))\n",
    "\n",
    "    sequence = []\n",
    "    for _ in range(length):\n",
    "        # Choose a cluster from target clusters\n",
    "        cluster = np.random.choice(target_clusters)\n",
    "\n",
    "        # Choose a random color from that cluster\n",
    "        if cluster in colors_in_clusters and colors_in_clusters[cluster]:\n",
    "            color = np.random.choice(colors_in_clusters[cluster])\n",
    "            sequence.append(color)\n",
    "\n",
    "    return sequence\n",
    "\n",
    "# Group colors by cluster\n",
    "colors_in_clusters = {}\n",
    "for color, cluster in color_to_cluster.items():\n",
    "    if cluster not in colors_in_clusters:\n",
    "        colors_in_clusters[cluster] = []\n",
    "    colors_in_clusters[cluster].append(color)\n",
    "\n",
    "# Generate new sequences based on specific sentiment clusters\n",
    "print(\"\\nGenerating New Sequences Based on Sentiment Clusters:\")\n",
    "for cluster in range(k):\n",
    "    new_sequence = generate_sequence_from_clusters(5, color_to_cluster, colors_in_clusters, [cluster])\n",
    "    momentum = calculate_momentum(new_sequence, color_to_cluster, cluster_weights)\n",
    "    print(f\"Sequence from Cluster {cluster}: {', '.join(new_sequence)} (Momentum: {momentum:.2f})\")\n",
    "\n",
    "# Generate a sequence with maximum expected momentum\n",
    "print(\"\\nGenerating a Sequence with Maximum Expected Momentum:\")\n",
    "# Find cluster pairs with highest weights\n",
    "flat_weights = cluster_weights.flatten()\n",
    "top_indices = np.argsort(flat_weights)[-5:]  # Top 5 transitions\n",
    "top_pairs = [(idx // k, idx % k) for idx in top_indices]\n",
    "\n",
    "# Create a sequence alternating between these clusters\n",
    "high_momentum_sequence = []\n",
    "for _ in range(5):  # Generate a sequence of length 10\n",
    "    pair = top_pairs[np.random.randint(0, len(top_pairs))]\n",
    "    if pair[0] in colors_in_clusters and colors_in_clusters[pair[0]]:\n",
    "        high_momentum_sequence.append(np.random.choice(colors_in_clusters[pair[0]]))\n",
    "    if pair[1] in colors_in_clusters and colors_in_clusters[pair[1]]:\n",
    "        high_momentum_sequence.append(np.random.choice(colors_in_clusters[pair[1]]))\n",
    "\n",
    "momentum = calculate_momentum(high_momentum_sequence, color_to_cluster, cluster_weights)\n",
    "print(f\"High momentum sequence: {', '.join(high_momentum_sequence)} (Momentum: {momentum:.2f})\")\n",
    "\n",
    "# Visualize the clusters in RGB space\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Define a list of distinct colors for visualization\n",
    "viz_colors = ['red', 'blue', 'green', 'purple', 'orange']\n",
    "\n",
    "for cluster in range(k):\n",
    "    cluster_colors = colors_df[colors_df['cluster'] == cluster]\n",
    "    ax.scatter(\n",
    "        cluster_colors['r'],\n",
    "        cluster_colors['g'],\n",
    "        cluster_colors['b'],\n",
    "        color=viz_colors[cluster % len(viz_colors)],\n",
    "        label=f'Cluster {cluster}',\n",
    "        alpha=0.7\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('Red')\n",
    "ax.set_ylabel('Green')\n",
    "ax.set_zlabel('Blue')\n",
    "ax.set_title('Color Clusters in RGB Space')\n",
    "plt.legend()\n",
    "\n",
    "# Create a visualization of cluster sentiment profiles\n",
    "sentiment_words = [col.replace('sentiment_', '') for col in sentiment_df.columns]\n",
    "cluster_sentiment_profiles = np.zeros((k, len(sentiment_words)))\n",
    "\n",
    "for cluster in range(k):\n",
    "    cluster_colors = colors_df[colors_df['cluster'] == cluster]\n",
    "    cluster_sentiment_profiles[cluster] = sentiment_df.loc[cluster_colors.index].mean().values\n",
    "\n",
    "# Select top 10 most distinguishing sentiment words\n",
    "sentiment_variance = np.var(cluster_sentiment_profiles, axis=0)\n",
    "top_sentiment_indices = np.argsort(sentiment_variance)[-10:]\n",
    "top_sentiment_words = [sentiment_words[i] for i in top_sentiment_indices]\n",
    "top_sentiment_profiles = cluster_sentiment_profiles[:, top_sentiment_indices]\n",
    "\n",
    "# Plot sentiment profiles\n",
    "plt.figure(figsize=(14, 8))\n",
    "bar_width = 0.15\n",
    "index = np.arange(len(top_sentiment_words))\n",
    "\n",
    "for i in range(k):\n",
    "    plt.bar(index + i * bar_width, top_sentiment_profiles[i], bar_width,\n",
    "            label=f'Cluster {i}', color=viz_colors[i % len(viz_colors)])\n",
    "\n",
    "plt.xlabel('Sentiment Words')\n",
    "plt.ylabel('Average Presence')\n",
    "plt.title('Sentiment Profiles by Cluster')\n",
    "plt.xticks(index + bar_width * (k-1)/2, top_sentiment_words, rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "print(\"\\nAnalysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nTfM2LxCUERv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_sbbnVO2UIpj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "executionInfo": {
     "elapsed": 773,
     "status": "ok",
     "timestamp": 1744680427544,
     "user": {
      "displayName": "Danielle Gauthier",
      "userId": "15668431405707832125"
     },
     "user_tz": 240
    },
    "id": "snAZYH2TDoPE",
    "outputId": "c9e2eb88-e8e0-4a3c-e111-e9f7a2d64ae7"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Calculate silhouette scores for different values of k\n",
    "silhouette_scores = []\n",
    "k_range = range(2, 10)  # Silhouette score requires at least 2 clusters\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(X)\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "\n",
    "# Plot silhouette scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, silhouette_scores, 'o-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Number of Clusters (k)', fontsize=12)\n",
    "plt.ylabel('Average Silhouette Score', fontsize=12)\n",
    "plt.title('Silhouette Analysis for Optimal k', fontsize=14)\n",
    "plt.xticks(k_range)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4246,
     "status": "ok",
     "timestamp": 1744680905141,
     "user": {
      "displayName": "Danielle Gauthier",
      "userId": "15668431405707832125"
     },
     "user_tz": 240
    },
    "id": "7inxt-yhE-0t",
    "outputId": "15d7d8f3-90f3-4b32-df14-e4ffa1faaf90"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import requests\n",
    "from io import StringIO\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import silhouette_score\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# URLs for the CSV files\n",
    "colors_url = \"https://hebbkx1anhila5yf.public.blob.vercel-storage.com/la%20matrice-qhiF8W1MZiXnmjlkL6xJasXeG1FryC.csv\"\n",
    "sequences_url = \"https://hebbkx1anhila5yf.public.blob.vercel-storage.com/la%20matrice%20sequences-2j9pbWxr7vXA22q5VUTWXYgyaSe9dO.csv\"\n",
    "\n",
    "# Function to fetch and parse CSV data\n",
    "def fetch_csv(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return pd.read_csv(StringIO(response.text))\n",
    "    else:\n",
    "        raise Exception(f\"Failed to fetch data: {response.status_code}\")\n",
    "\n",
    "# Fetch the data\n",
    "print(\"Fetching color data...\")\n",
    "colors_df = fetch_csv(colors_url)\n",
    "print(\"Fetching sequence data...\")\n",
    "sequences_df = fetch_csv(sequences_url)\n",
    "\n",
    "# Display the first few rows of each dataset\n",
    "print(\"\\nColor Data Sample:\")\n",
    "print(colors_df.head())\n",
    "print(\"\\nSequence Data Sample:\")\n",
    "print(sequences_df.head())\n",
    "\n",
    "# Clean and prepare the color sentiment data\n",
    "print(\"\\nPreparing color sentiment data using 'matrice1' column...\")\n",
    "\n",
    "# Make sure RGB values are numeric\n",
    "for col in ['r', 'g', 'b']:\n",
    "    colors_df[col] = pd.to_numeric(colors_df[col], errors='coerce')\n",
    "\n",
    "# Create one-hot encoding for matrice1 values\n",
    "colors_df['matrice1'] = colors_df['matrice1'].fillna('Unknown').astype(str)\n",
    "matrice1_dummies = pd.get_dummies(colors_df['matrice1'], prefix='matrice1')\n",
    "\n",
    "# Combine RGB values with matrice1 features\n",
    "X_rgb = colors_df[['r', 'g', 'b']].fillna(0)\n",
    "X = pd.concat([X_rgb, matrice1_dummies], axis=1)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Determine optimal number of clusters using the elbow method\n",
    "inertia = []\n",
    "k_range = range(2, 10)\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the elbow curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, inertia, 'o-')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.grid(True)\n",
    "print(\"Determining optimal number of clusters...\")\n",
    "\n",
    "# Calculate silhouette scores\n",
    "silhouette_scores = []\n",
    "for k in range(2, 10):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(X_scaled)\n",
    "    silhouette_avg = silhouette_score(X_scaled, cluster_labels)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "\n",
    "# Plot silhouette scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(2, 10), silhouette_scores, 'o-')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Analysis for Optimal k')\n",
    "plt.grid(True)\n",
    "\n",
    "# Choose k=5 based on analysis\n",
    "k = 5\n",
    "print(f\"\\nPerforming k-means clustering with k={k}...\")\n",
    "kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "colors_df['cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Visualize the clusters using PCA for dimensionality reduction\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for cluster in range(k):\n",
    "    plt.scatter(\n",
    "        X_pca[colors_df['cluster'] == cluster, 0],\n",
    "        X_pca[colors_df['cluster'] == cluster, 1],\n",
    "        label=f'Cluster {cluster}',\n",
    "        alpha=0.7\n",
    "    )\n",
    "plt.title('Color Sentiment Clusters (PCA)')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Analyze the clusters\n",
    "print(\"\\nCluster Analysis:\")\n",
    "for cluster in range(k):\n",
    "    cluster_colors = colors_df[colors_df['cluster'] == cluster]\n",
    "    print(f\"\\nCluster {cluster} ({len(cluster_colors)} colors):\")\n",
    "    print(f\"  Common colors: {', '.join(cluster_colors['color'].value_counts().head(5).index.tolist())}\")\n",
    "\n",
    "    # Find most common matrice1 values in this cluster\n",
    "    matrice1_counts = cluster_colors['matrice1'].value_counts().head(5)\n",
    "    print(f\"  Top matrice1 values: {', '.join(matrice1_counts.index.tolist())}\")\n",
    "\n",
    "    # Average RGB values for this cluster\n",
    "    avg_rgb = cluster_colors[['r', 'g', 'b']].mean()\n",
    "    print(f\"  Average RGB: ({avg_rgb['r']:.1f}, {avg_rgb['g']:.1f}, {avg_rgb['b']:.1f})\")\n",
    "\n",
    "# Create a color-to-cluster mapping\n",
    "color_to_cluster = dict(zip(colors_df['color'], colors_df['cluster']))\n",
    "\n",
    "# Parse the sequences\n",
    "print(\"\\nAnalyzing color sequences...\")\n",
    "def parse_sequence(seq_str):\n",
    "    if pd.isna(seq_str):\n",
    "        return []\n",
    "    return [color.strip().lower() for color in seq_str.split(',')]\n",
    "\n",
    "sequences_df['parsed_sequence'] = sequences_df['sequence'].apply(parse_sequence)\n",
    "\n",
    "# Calculate sequence momentum based on cluster transitions\n",
    "def calculate_momentum(sequence, color_to_cluster, cluster_weights=None):\n",
    "    if cluster_weights is None:\n",
    "        # Default weights: transitions between different clusters have higher momentum\n",
    "        cluster_weights = np.ones((k, k)) - np.eye(k)\n",
    "\n",
    "    momentum = 0\n",
    "    valid_transitions = 0\n",
    "\n",
    "    for i in range(len(sequence) - 1):\n",
    "        color1 = sequence[i]\n",
    "        color2 = sequence[i + 1]\n",
    "\n",
    "        # Skip if colors not in our dataset\n",
    "        if color1 not in color_to_cluster or color2 not in color_to_cluster:\n",
    "            continue\n",
    "\n",
    "        cluster1 = color_to_cluster[color1]\n",
    "        cluster2 = color_to_cluster[color2]\n",
    "\n",
    "        # Add momentum based on cluster transition\n",
    "        momentum += cluster_weights[cluster1, cluster2]\n",
    "        valid_transitions += 1\n",
    "\n",
    "    # Return average momentum per transition to normalize for sequence length\n",
    "    return momentum / max(1, valid_transitions)\n",
    "\n",
    "# Define cluster transition weights based on matrice1 similarity\n",
    "# Calculate matrice1 similarity between clusters\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "# Extract just the matrice1 part of the cluster centers (not RGB)\n",
    "matrice1_centers = cluster_centers[:, 3:]\n",
    "# Calculate cosine similarity between matrice1 centers\n",
    "matrice1_similarity = np.zeros((k, k))\n",
    "for i in range(k):\n",
    "    for j in range(k):\n",
    "        # Dot product of normalized vectors = cosine similarity\n",
    "        norm_i = np.linalg.norm(matrice1_centers[i])\n",
    "        norm_j = np.linalg.norm(matrice1_centers[j])\n",
    "        if norm_i > 0 and norm_j > 0:\n",
    "            matrice1_similarity[i, j] = np.dot(matrice1_centers[i], matrice1_centers[j]) / (norm_i * norm_j)\n",
    "        else:\n",
    "            matrice1_similarity[i, j] = 0\n",
    "\n",
    "# Convert similarity to weights (higher similarity = lower momentum)\n",
    "cluster_weights = 1 - matrice1_similarity\n",
    "\n",
    "# Visualize the cluster transition weights as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(cluster_weights, cmap='viridis', interpolation='nearest')\n",
    "plt.colorbar(label='Momentum Weight')\n",
    "plt.title('Cluster Transition Momentum Weights')\n",
    "plt.xlabel('To Cluster')\n",
    "plt.ylabel('From Cluster')\n",
    "for i in range(k):\n",
    "    for j in range(k):\n",
    "        plt.text(j, i, f'{cluster_weights[i, j]:.2f}',\n",
    "                 ha='center', va='center',\n",
    "                 color='white' if cluster_weights[i, j] > 0.5 else 'black')\n",
    "plt.xticks(range(k))\n",
    "plt.yticks(range(k))\n",
    "\n",
    "# Calculate momentum for each sequence\n",
    "sequences_df['momentum'] = sequences_df['parsed_sequence'].apply(\n",
    "    lambda seq: calculate_momentum(seq, color_to_cluster, cluster_weights)\n",
    ")\n",
    "\n",
    "# Find sequences with highest and lowest momentum\n",
    "print(\"\\nSequences with Highest Momentum:\")\n",
    "high_momentum = sequences_df.sort_values('momentum', ascending=False).head(5)\n",
    "for _, row in high_momentum.iterrows():\n",
    "    print(f\"  {row['ï»¿name']}: {row['sequence']} (Momentum: {row['momentum']:.2f})\")\n",
    "\n",
    "print(\"\\nSequences with Lowest Momentum:\")\n",
    "low_momentum = sequences_df.sort_values('momentum').head(5)\n",
    "for _, row in low_momentum.iterrows():\n",
    "    print(f\"  {row['ï»¿name']}: {row['sequence']} (Momentum: {row['momentum']:.2f})\")\n",
    "\n",
    "# Function to optimize a sequence by maximizing or minimizing momentum\n",
    "def optimize_sequence(sequence, color_to_cluster, cluster_weights, maximize=True, iterations=100):\n",
    "    colors_in_clusters = {}\n",
    "    for color, cluster in color_to_cluster.items():\n",
    "        if cluster not in colors_in_clusters:\n",
    "            colors_in_clusters[cluster] = []\n",
    "        colors_in_clusters[cluster].append(color)\n",
    "\n",
    "    best_sequence = sequence.copy()\n",
    "    best_momentum = calculate_momentum(best_sequence, color_to_cluster, cluster_weights)\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        # Randomly select a position to modify\n",
    "        if len(sequence) == 0:\n",
    "            continue\n",
    "        pos = np.random.randint(0, len(sequence))\n",
    "\n",
    "        # Get current color and its cluster\n",
    "        if sequence[pos] not in color_to_cluster:\n",
    "            continue\n",
    "        current_cluster = color_to_cluster[sequence[pos]]\n",
    "\n",
    "        # Choose a random different cluster and a random color from it\n",
    "        other_clusters = [c for c in range(k) if c != current_cluster and c in colors_in_clusters]\n",
    "        if not other_clusters:\n",
    "            continue\n",
    "        new_cluster = np.random.choice(other_clusters)\n",
    "        new_color = np.random.choice(colors_in_clusters[new_cluster])\n",
    "\n",
    "        # Create a new sequence with the modified color\n",
    "        new_sequence = sequence.copy()\n",
    "        new_sequence[pos] = new_color\n",
    "\n",
    "        # Calculate new momentum\n",
    "        new_momentum = calculate_momentum(new_sequence, color_to_cluster, cluster_weights)\n",
    "\n",
    "        # Update if better (higher momentum if maximizing, lower if minimizing)\n",
    "        if (maximize and new_momentum > best_momentum) or (not maximize and new_momentum < best_momentum):\n",
    "            best_sequence = new_sequence\n",
    "            best_momentum = new_momentum\n",
    "\n",
    "    return best_sequence, best_momentum\n",
    "\n",
    "# Example: Optimize a sequence to maximize momentum\n",
    "print(\"\\nOptimizing Sequences:\")\n",
    "sample_sequence = sequences_df.iloc[0]['parsed_sequence']\n",
    "if len(sample_sequence) > 0:\n",
    "    print(f\"Original sequence: {', '.join(sample_sequence)}\")\n",
    "\n",
    "    # Maximize momentum\n",
    "    optimized_max, max_momentum = optimize_sequence(\n",
    "        sample_sequence, color_to_cluster, cluster_weights, maximize=True\n",
    "    )\n",
    "    print(f\"Optimized for maximum momentum: {', '.join(optimized_max)} (Momentum: {max_momentum:.2f})\")\n",
    "\n",
    "    # Minimize momentum\n",
    "    optimized_min, min_momentum = optimize_sequence(\n",
    "        sample_sequence, color_to_cluster, cluster_weights, maximize=False\n",
    "    )\n",
    "    print(f\"Optimized for minimum momentum: {', '.join(optimized_min)} (Momentum: {min_momentum:.2f})\")\n",
    "\n",
    "# Create a function to generate new sequences based on matrice1 clusters\n",
    "def generate_sequence_from_clusters(length, color_to_cluster, colors_in_clusters, target_clusters=None):\n",
    "    if target_clusters is None:\n",
    "        target_clusters = list(range(k))\n",
    "\n",
    "    sequence = []\n",
    "    for _ in range(length):\n",
    "        # Choose a cluster from target clusters\n",
    "        cluster = np.random.choice(target_clusters)\n",
    "\n",
    "        # Choose a random color from that cluster\n",
    "        if cluster in colors_in_clusters and colors_in_clusters[cluster]:\n",
    "            color = np.random.choice(colors_in_clusters[cluster])\n",
    "            sequence.append(color)\n",
    "\n",
    "    return sequence\n",
    "\n",
    "# Group colors by cluster\n",
    "colors_in_clusters = {}\n",
    "for color, cluster in color_to_cluster.items():\n",
    "    if cluster not in colors_in_clusters:\n",
    "        colors_in_clusters[cluster] = []\n",
    "    colors_in_clusters[cluster].append(color)\n",
    "\n",
    "# Generate new sequences based on specific matrice1 clusters\n",
    "print(\"\\nGenerating New Sequences Based on Matrice1 Clusters:\")\n",
    "for cluster in range(k):\n",
    "    new_sequence = generate_sequence_from_clusters(5, color_to_cluster, colors_in_clusters, [cluster])\n",
    "    momentum = calculate_momentum(new_sequence, color_to_cluster, cluster_weights)\n",
    "    print(f\"Sequence from Cluster {cluster}: {', '.join(new_sequence)} (Momentum: {momentum:.2f})\")\n",
    "\n",
    "# Generate a sequence with maximum expected momentum\n",
    "print(\"\\nGenerating a Sequence with Maximum Expected Momentum:\")\n",
    "# Find cluster pairs with highest weights\n",
    "flat_weights = cluster_weights.flatten()\n",
    "top_indices = np.argsort(flat_weights)[-5:]  # Top 5 transitions\n",
    "top_pairs = [(idx // k, idx % k) for idx in top_indices]\n",
    "\n",
    "# Create a sequence alternating between these clusters\n",
    "high_momentum_sequence = []\n",
    "for _ in range(5):  # Generate a sequence of length 10\n",
    "    pair = top_pairs[np.random.randint(0, len(top_pairs))]\n",
    "    if pair[0] in colors_in_clusters and colors_in_clusters[pair[0]]:\n",
    "        high_momentum_sequence.append(np.random.choice(colors_in_clusters[pair[0]]))\n",
    "    if pair[1] in colors_in_clusters and colors_in_clusters[pair[1]]:\n",
    "        high_momentum_sequence.append(np.random.choice(colors_in_clusters[pair[1]]))\n",
    "\n",
    "momentum = calculate_momentum(high_momentum_sequence, color_to_cluster, cluster_weights)\n",
    "print(f\"High momentum sequence: {', '.join(high_momentum_sequence)} (Momentum: {momentum:.2f})\")\n",
    "\n",
    "# Visualize the clusters in RGB space\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Define a list of distinct colors for visualization\n",
    "viz_colors = ['red', 'blue', 'green', 'purple', 'orange']\n",
    "\n",
    "for cluster in range(k):\n",
    "    cluster_colors = colors_df[colors_df['cluster'] == cluster]\n",
    "    ax.scatter(\n",
    "        cluster_colors['r'],\n",
    "        cluster_colors['g'],\n",
    "        cluster_colors['b'],\n",
    "        color=viz_colors[cluster % len(viz_colors)],\n",
    "        label=f'Cluster {cluster}',\n",
    "        alpha=0.7\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('Red')\n",
    "ax.set_ylabel('Green')\n",
    "ax.set_zlabel('Blue')\n",
    "ax.set_title('Color Clusters in RGB Space')\n",
    "plt.legend()\n",
    "\n",
    "# Create a visualization of cluster matrice1 profiles\n",
    "# Get all unique matrice1 values\n",
    "unique_matrice1 = colors_df['matrice1'].unique()\n",
    "matrice1_counts = np.zeros((k, len(unique_matrice1)))\n",
    "\n",
    "for cluster in range(k):\n",
    "    cluster_colors = colors_df[colors_df['cluster'] == cluster]\n",
    "    for i, matrice1 in enumerate(unique_matrice1):\n",
    "        matrice1_counts[cluster, i] = (cluster_colors['matrice1'] == matrice1).sum() / len(cluster_colors)\n",
    "\n",
    "# Plot matrice1 profiles\n",
    "plt.figure(figsize=(14, 8))\n",
    "bar_width = 0.15\n",
    "index = np.arange(len(unique_matrice1))\n",
    "\n",
    "for i in range(k):\n",
    "    plt.bar(index + i * bar_width, matrice1_counts[i], bar_width,\n",
    "            label=f'Cluster {i}', color=viz_colors[i % len(viz_colors)])\n",
    "\n",
    "plt.xlabel('Matrice1 Values')\n",
    "plt.ylabel('Proportion in Cluster')\n",
    "plt.title('Matrice1 Profiles by Cluster')\n",
    "plt.xticks(index + bar_width * (k-1)/2, unique_matrice1, rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Create a visualization of the emotional trajectory of sequences\n",
    "def plot_sequence_trajectory(sequence_name, sequence, color_to_cluster):\n",
    "    valid_colors = [color for color in sequence if color in color_to_cluster]\n",
    "    if len(valid_colors) < 2:\n",
    "        return\n",
    "\n",
    "    clusters = [color_to_cluster[color] for color in valid_colors]\n",
    "\n",
    "    # Get RGB values for each color\n",
    "    rgb_values = []\n",
    "    for color in valid_colors:\n",
    "        color_row = colors_df[colors_df['color'] == color].iloc[0]\n",
    "        rgb_values.append((color_row['r'], color_row['g'], color_row['b']))\n",
    "\n",
    "    # Plot the trajectory in RGB space\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Plot points\n",
    "    for i, (r, g, b) in enumerate(rgb_values):\n",
    "        ax.scatter(r, g, b, color=viz_colors[clusters[i]], s=100, label=f'{valid_colors[i]} (Cluster {clusters[i]})' if i == 0 else \"\")\n",
    "\n",
    "    # Plot lines connecting points\n",
    "    for i in range(len(rgb_values) - 1):\n",
    "        ax.plot([rgb_values[i][0], rgb_values[i+1][0]],\n",
    "                [rgb_values[i][1], rgb_values[i+1][1]],\n",
    "                [rgb_values[i][2], rgb_values[i+1][2]],\n",
    "                'k-', alpha=0.5)\n",
    "\n",
    "    # Add arrows to show direction\n",
    "    for i in range(len(rgb_values) - 1):\n",
    "        ax.quiver(rgb_values[i][0], rgb_values[i][1], rgb_values[i][2],\n",
    "                 rgb_values[i+1][0] - rgb_values[i][0],\n",
    "                 rgb_values[i+1][1] - rgb_values[i][1],\n",
    "                 rgb_values[i+1][2] - rgb_values[i][2],\n",
    "                 color='black', arrow_length_ratio=0.1)\n",
    "\n",
    "    ax.set_xlabel('Red')\n",
    "    ax.set_ylabel('Green')\n",
    "    ax.set_zlabel('Blue')\n",
    "    ax.set_title(f'Color Trajectory: {sequence_name}')\n",
    "\n",
    "    # Add color names as annotations\n",
    "    for i, (r, g, b) in enumerate(rgb_values):\n",
    "        ax.text(r, g, b, f'  {valid_colors[i]}', size=10)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "# Plot trajectories for a few example sequences\n",
    "print(\"\\nPlotting color trajectories for example sequences...\")\n",
    "for _, row in sequences_df.head(3).iterrows():\n",
    "    plot_sequence_trajectory(row['ï»¿name'], row['parsed_sequence'], color_to_cluster)\n",
    "\n",
    "print(\"\\nAnalysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 7274,
     "status": "ok",
     "timestamp": 1744681284637,
     "user": {
      "displayName": "Danielle Gauthier",
      "userId": "15668431405707832125"
     },
     "user_tz": 240
    },
    "id": "EyDSscDXG4Ms",
    "outputId": "a36da57d-56b4-43fe-a4a1-61fe540283cf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import requests\n",
    "from io import StringIO\n",
    "import re\n",
    "from sklearn.metrics import silhouette_score\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# URLs for the CSV files\n",
    "colors_url = \"https://hebbkx1anhila5yf.public.blob.vercel-storage.com/la%20matrice-qhiF8W1MZiXnmjlkL6xJasXeG1FryC.csv\"\n",
    "sequences_url = \"https://hebbkx1anhila5yf.public.blob.vercel-storage.com/la%20matrice%20sequences-2j9pbWxr7vXA22q5VUTWXYgyaSe9dO.csv\"\n",
    "\n",
    "# Function to fetch and parse CSV data\n",
    "def fetch_csv(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return pd.read_csv(StringIO(response.text))\n",
    "    else:\n",
    "        raise Exception(f\"Failed to fetch data: {response.status_code}\")\n",
    "\n",
    "# Fetch the data\n",
    "print(\"Fetching color data...\")\n",
    "colors_df = fetch_csv(colors_url)\n",
    "print(\"Fetching sequence data...\")\n",
    "sequences_df = fetch_csv(sequences_url)\n",
    "\n",
    "# Display the first few rows of each dataset\n",
    "print(\"\\nColor Data Sample:\")\n",
    "print(colors_df.head())\n",
    "print(\"\\nSequence Data Sample:\")\n",
    "print(sequences_df.head())\n",
    "\n",
    "# Clean and prepare the color sentiment data\n",
    "print(\"\\nPreparing color sentiment data using 'matrice' column...\")\n",
    "\n",
    "# Make sure RGB values are numeric\n",
    "for col in ['r', 'g', 'b']:\n",
    "    colors_df[col] = pd.to_numeric(colors_df[col], errors='coerce')\n",
    "\n",
    "# Create one-hot encoding for matrice values\n",
    "colors_df['matrice'] = colors_df['matrice'].fillna('Unknown').astype(str)\n",
    "matrice_dummies = pd.get_dummies(colors_df['matrice'], prefix='matrice')\n",
    "\n",
    "# Combine RGB values with matrice features\n",
    "X_rgb = colors_df[['r', 'g', 'b']].fillna(0)\n",
    "X = pd.concat([X_rgb, matrice_dummies], axis=1)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Determine optimal number of clusters using the elbow method\n",
    "inertia = []\n",
    "k_range = range(2, 10)\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the elbow curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, inertia, 'o-')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.grid(True)\n",
    "print(\"Determining optimal number of clusters...\")\n",
    "\n",
    "# Calculate silhouette scores\n",
    "silhouette_scores = []\n",
    "for k in range(2, 10):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(X_scaled)\n",
    "    silhouette_avg = silhouette_score(X_scaled, cluster_labels)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "\n",
    "# Plot silhouette scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(2, 10), silhouette_scores, 'o-')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Analysis for Optimal k')\n",
    "plt.grid(True)\n",
    "\n",
    "# Choose k=5 based on analysis\n",
    "k = 5\n",
    "print(f\"\\nPerforming k-means clustering with k={k}...\")\n",
    "kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "colors_df['cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Visualize the clusters using PCA for dimensionality reduction\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for cluster in range(k):\n",
    "    plt.scatter(\n",
    "        X_pca[colors_df['cluster'] == cluster, 0],\n",
    "        X_pca[colors_df['cluster'] == cluster, 1],\n",
    "        label=f'Cluster {cluster}',\n",
    "        alpha=0.7\n",
    "    )\n",
    "plt.title('Color Sentiment Clusters (PCA)')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Analyze the clusters\n",
    "print(\"\\nCluster Analysis:\")\n",
    "for cluster in range(k):\n",
    "    cluster_colors = colors_df[colors_df['cluster'] == cluster]\n",
    "    print(f\"\\nCluster {cluster} ({len(cluster_colors)} colors):\")\n",
    "    print(f\"  Common colors: {', '.join(cluster_colors['color'].value_counts().head(5).index.tolist())}\")\n",
    "\n",
    "    # Find most common matrice values in this cluster\n",
    "    matrice_counts = cluster_colors['matrice'].value_counts().head(5)\n",
    "    print(f\"  Top matrice values: {', '.join(matrice_counts.index.tolist())}\")\n",
    "\n",
    "    # Average RGB values for this cluster\n",
    "    avg_rgb = cluster_colors[['r', 'g', 'b']].mean()\n",
    "    print(f\"  Average RGB: ({avg_rgb['r']:.1f}, {avg_rgb['g']:.1f}, {avg_rgb['b']:.1f})\")\n",
    "\n",
    "# Create a color-to-cluster mapping\n",
    "color_to_cluster = dict(zip(colors_df['color'], colors_df['cluster']))\n",
    "\n",
    "# Parse the sequences\n",
    "print(\"\\nAnalyzing color sequences...\")\n",
    "def parse_sequence(seq_str):\n",
    "    if pd.isna(seq_str):\n",
    "        return []\n",
    "    return [color.strip().lower() for color in seq_str.split(',')]\n",
    "\n",
    "sequences_df['parsed_sequence'] = sequences_df['sequence'].apply(parse_sequence)\n",
    "\n",
    "# Calculate sequence momentum based on cluster transitions\n",
    "def calculate_momentum(sequence, color_to_cluster, cluster_weights=None):\n",
    "    if cluster_weights is None:\n",
    "        # Default weights: transitions between different clusters have higher momentum\n",
    "        cluster_weights = np.ones((k, k)) - np.eye(k)\n",
    "\n",
    "    momentum = 0\n",
    "    valid_transitions = 0\n",
    "\n",
    "    for i in range(len(sequence) - 1):\n",
    "        color1 = sequence[i]\n",
    "        color2 = sequence[i + 1]\n",
    "\n",
    "        # Skip if colors not in our dataset\n",
    "        if color1 not in color_to_cluster or color2 not in color_to_cluster:\n",
    "            continue\n",
    "\n",
    "        cluster1 = color_to_cluster[color1]\n",
    "        cluster2 = color_to_cluster[color2]\n",
    "\n",
    "        # Add momentum based on cluster transition\n",
    "        momentum += cluster_weights[cluster1, cluster2]\n",
    "        valid_transitions += 1\n",
    "\n",
    "    # Return average momentum per transition to normalize for sequence length\n",
    "    return momentum / max(1, valid_transitions)\n",
    "\n",
    "# Define cluster transition weights based on matrice similarity\n",
    "# Calculate matrice similarity between clusters\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "# Extract just the matrice part of the cluster centers (not RGB)\n",
    "matrice_centers = cluster_centers[:, 3:]\n",
    "# Calculate cosine similarity between matrice centers\n",
    "matrice_similarity = np.zeros((k, k))\n",
    "for i in range(k):\n",
    "    for j in range(k):\n",
    "        # Dot product of normalized vectors = cosine similarity\n",
    "        norm_i = np.linalg.norm(matrice_centers[i])\n",
    "        norm_j = np.linalg.norm(matrice_centers[j])\n",
    "        if norm_i > 0 and norm_j > 0:\n",
    "            matrice_similarity[i, j] = np.dot(matrice_centers[i], matrice_centers[j]) / (norm_i * norm_j)\n",
    "        else:\n",
    "            matrice_similarity[i, j] = 0\n",
    "\n",
    "# Convert similarity to weights (higher similarity = lower momentum)\n",
    "cluster_weights = 1 - matrice_similarity\n",
    "\n",
    "# Visualize the cluster transition weights as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(cluster_weights, cmap='viridis', interpolation='nearest')\n",
    "plt.colorbar(label='Momentum Weight')\n",
    "plt.title('Cluster Transition Momentum Weights')\n",
    "plt.xlabel('To Cluster')\n",
    "plt.ylabel('From Cluster')\n",
    "for i in range(k):\n",
    "    for j in range(k):\n",
    "        plt.text(j, i, f'{cluster_weights[i, j]:.2f}',\n",
    "                 ha='center', va='center',\n",
    "                 color='white' if cluster_weights[i, j] > 0.5 else 'black')\n",
    "plt.xticks(range(k))\n",
    "plt.yticks(range(k))\n",
    "\n",
    "# Calculate momentum for each sequence\n",
    "sequences_df['momentum'] = sequences_df['parsed_sequence'].apply(\n",
    "    lambda seq: calculate_momentum(seq, color_to_cluster, cluster_weights)\n",
    ")\n",
    "\n",
    "# Find sequences with highest and lowest momentum\n",
    "print(\"\\nSequences with Highest Momentum:\")\n",
    "high_momentum = sequences_df.sort_values('momentum', ascending=False).head(5)\n",
    "for _, row in high_momentum.iterrows():\n",
    "    print(f\"  {row['ï»¿name']}: {row['sequence']} (Momentum: {row['momentum']:.2f})\")\n",
    "\n",
    "print(\"\\nSequences with Lowest Momentum:\")\n",
    "low_momentum = sequences_df.sort_values('momentum').head(5)\n",
    "for _, row in low_momentum.iterrows():\n",
    "    print(f\"  {row['ï»¿name']}: {row['sequence']} (Momentum: {row['momentum']:.2f})\")\n",
    "\n",
    "# Function to optimize a sequence by maximizing or minimizing momentum\n",
    "def optimize_sequence(sequence, color_to_cluster, cluster_weights, maximize=True, iterations=100):\n",
    "    colors_in_clusters = {}\n",
    "    for color, cluster in color_to_cluster.items():\n",
    "        if cluster not in colors_in_clusters:\n",
    "            colors_in_clusters[cluster] = []\n",
    "        colors_in_clusters[cluster].append(color)\n",
    "\n",
    "    best_sequence = sequence.copy()\n",
    "    best_momentum = calculate_momentum(best_sequence, color_to_cluster, cluster_weights)\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        # Randomly select a position to modify\n",
    "        if len(sequence) == 0:\n",
    "            continue\n",
    "        pos = np.random.randint(0, len(sequence))\n",
    "\n",
    "        # Get current color and its cluster\n",
    "        if sequence[pos] not in color_to_cluster:\n",
    "            continue\n",
    "        current_cluster = color_to_cluster[sequence[pos]]\n",
    "\n",
    "        # Choose a random different cluster and a random color from it\n",
    "        other_clusters = [c for c in range(k) if c != current_cluster and c in colors_in_clusters]\n",
    "        if not other_clusters:\n",
    "            continue\n",
    "        new_cluster = np.random.choice(other_clusters)\n",
    "        new_color = np.random.choice(colors_in_clusters[new_cluster])\n",
    "\n",
    "        # Create a new sequence with the modified color\n",
    "        new_sequence = sequence.copy()\n",
    "        new_sequence[pos] = new_color\n",
    "\n",
    "        # Calculate new momentum\n",
    "        new_momentum = calculate_momentum(new_sequence, color_to_cluster, cluster_weights)\n",
    "\n",
    "        # Update if better (higher momentum if maximizing, lower if minimizing)\n",
    "        if (maximize and new_momentum > best_momentum) or (not maximize and new_momentum < best_momentum):\n",
    "            best_sequence = new_sequence\n",
    "            best_momentum = new_momentum\n",
    "\n",
    "    return best_sequence, best_momentum\n",
    "\n",
    "# Example: Optimize a sequence to maximize momentum\n",
    "print(\"\\nOptimizing Sequences:\")\n",
    "sample_sequence = sequences_df.iloc[0]['parsed_sequence']\n",
    "if len(sample_sequence) > 0:\n",
    "    print(f\"Original sequence: {', '.join(sample_sequence)}\")\n",
    "\n",
    "    # Maximize momentum\n",
    "    optimized_max, max_momentum = optimize_sequence(\n",
    "        sample_sequence, color_to_cluster, cluster_weights, maximize=True\n",
    "    )\n",
    "    print(f\"Optimized for maximum momentum: {', '.join(optimized_max)} (Momentum: {max_momentum:.2f})\")\n",
    "\n",
    "    # Minimize momentum\n",
    "    optimized_min, min_momentum = optimize_sequence(\n",
    "        sample_sequence, color_to_cluster, cluster_weights, maximize=False\n",
    "    )\n",
    "    print(f\"Optimized for minimum momentum: {', '.join(optimized_min)} (Momentum: {min_momentum:.2f})\")\n",
    "\n",
    "# Create a function to generate new sequences based on matrice clusters\n",
    "def generate_sequence_from_clusters(length, color_to_cluster, colors_in_clusters, target_clusters=None):\n",
    "    if target_clusters is None:\n",
    "        target_clusters = list(range(k))\n",
    "\n",
    "    sequence = []\n",
    "    for _ in range(length):\n",
    "        # Choose a cluster from target clusters\n",
    "        cluster = np.random.choice(target_clusters)\n",
    "\n",
    "        # Choose a random color from that cluster\n",
    "        if cluster in colors_in_clusters and colors_in_clusters[cluster]:\n",
    "            color = np.random.choice(colors_in_clusters[cluster])\n",
    "            sequence.append(color)\n",
    "\n",
    "    return sequence\n",
    "\n",
    "# Group colors by cluster\n",
    "colors_in_clusters = {}\n",
    "for color, cluster in color_to_cluster.items():\n",
    "    if cluster not in colors_in_clusters:\n",
    "        colors_in_clusters[cluster] = []\n",
    "    colors_in_clusters[cluster].append(color)\n",
    "\n",
    "# Generate new sequences based on specific matrice clusters\n",
    "print(\"\\nGenerating New Sequences Based on Matrice Clusters:\")\n",
    "for cluster in range(k):\n",
    "    new_sequence = generate_sequence_from_clusters(5, color_to_cluster, colors_in_clusters, [cluster])\n",
    "    momentum = calculate_momentum(new_sequence, color_to_cluster, cluster_weights)\n",
    "    print(f\"Sequence from Cluster {cluster}: {', '.join(new_sequence)} (Momentum: {momentum:.2f})\")\n",
    "\n",
    "# Generate a sequence with maximum expected momentum\n",
    "print(\"\\nGenerating a Sequence with Maximum Expected Momentum:\")\n",
    "# Find cluster pairs with highest weights\n",
    "flat_weights = cluster_weights.flatten()\n",
    "top_indices = np.argsort(flat_weights)[-5:]  # Top 5 transitions\n",
    "top_pairs = [(idx // k, idx % k) for idx in top_indices]\n",
    "\n",
    "# Create a sequence alternating between these clusters\n",
    "high_momentum_sequence = []\n",
    "for _ in range(5):  # Generate a sequence of length 10\n",
    "    pair = top_pairs[np.random.randint(0, len(top_pairs))]\n",
    "    if pair[0] in colors_in_clusters and colors_in_clusters[pair[0]]:\n",
    "        high_momentum_sequence.append(np.random.choice(colors_in_clusters[pair[0]]))\n",
    "    if pair[1] in colors_in_clusters and colors_in_clusters[pair[1]]:\n",
    "        high_momentum_sequence.append(np.random.choice(colors_in_clusters[pair[1]]))\n",
    "\n",
    "momentum = calculate_momentum(high_momentum_sequence, color_to_cluster, cluster_weights)\n",
    "print(f\"High momentum sequence: {', '.join(high_momentum_sequence)} (Momentum: {momentum:.2f})\")\n",
    "\n",
    "# Visualize the clusters in RGB space\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Define a list of distinct colors for visualization\n",
    "viz_colors = ['red', 'blue', 'green', 'purple', 'orange']\n",
    "\n",
    "for cluster in range(k):\n",
    "    cluster_colors = colors_df[colors_df['cluster'] == cluster]\n",
    "    ax.scatter(\n",
    "        cluster_colors['r'],\n",
    "        cluster_colors['g'],\n",
    "        cluster_colors['b'],\n",
    "        color=viz_colors[cluster % len(viz_colors)],\n",
    "        label=f'Cluster {cluster}',\n",
    "        alpha=0.7\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('Red')\n",
    "ax.set_ylabel('Green')\n",
    "ax.set_zlabel('Blue')\n",
    "ax.set_title('Color Clusters in RGB Space')\n",
    "plt.legend()\n",
    "\n",
    "# Create a visualization of cluster matrice profiles\n",
    "# Get all unique matrice values\n",
    "unique_matrice = colors_df['matrice'].unique()\n",
    "matrice_counts = np.zeros((k, len(unique_matrice)))\n",
    "\n",
    "for cluster in range(k):\n",
    "    cluster_colors = colors_df[colors_df['cluster'] == cluster]\n",
    "    for i, matrice in enumerate(unique_matrice):\n",
    "        matrice_counts[cluster, i] = (cluster_colors['matrice'] == matrice).sum() / len(cluster_colors)\n",
    "\n",
    "# Plot matrice profiles\n",
    "plt.figure(figsize=(14, 8))\n",
    "bar_width = 0.15\n",
    "index = np.arange(len(unique_matrice))\n",
    "\n",
    "for i in range(k):\n",
    "    plt.bar(index + i * bar_width, matrice_counts[i], bar_width,\n",
    "            label=f'Cluster {i}', color=viz_colors[i % len(viz_colors)])\n",
    "\n",
    "plt.xlabel('Matrice Values')\n",
    "plt.ylabel('Proportion in Cluster')\n",
    "plt.title('Matrice Profiles by Cluster')\n",
    "plt.xticks(index + bar_width * (k-1)/2, unique_matrice, rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Create a visualization of the emotional trajectory of sequences\n",
    "def plot_sequence_trajectory(sequence_name, sequence, color_to_cluster):\n",
    "    valid_colors = [color for color in sequence if color in color_to_cluster]\n",
    "    if len(valid_colors) < 2:\n",
    "        return\n",
    "\n",
    "    clusters = [color_to_cluster[color] for color in valid_colors]\n",
    "\n",
    "    # Get RGB values for each color\n",
    "    rgb_values = []\n",
    "    matrice_values = []\n",
    "    for color in valid_colors:\n",
    "        color_row = colors_df[colors_df['color'] == color].iloc[0]\n",
    "        rgb_values.append((color_row['r'], color_row['g'], color_row['b']))\n",
    "        matrice_values.append(color_row['matrice'])\n",
    "\n",
    "    # Plot the trajectory in RGB space\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Plot points\n",
    "    for i, (r, g, b) in enumerate(rgb_values):\n",
    "        ax.scatter(r, g, b, color=viz_colors[clusters[i]], s=100, label=f'{valid_colors[i]} (Cluster {clusters[i]})' if i == 0 else \"\")\n",
    "\n",
    "    # Plot lines connecting points\n",
    "    for i in range(len(rgb_values) - 1):\n",
    "        ax.plot([rgb_values[i][0], rgb_values[i+1][0]],\n",
    "                [rgb_values[i][1], rgb_values[i+1][1]],\n",
    "                [rgb_values[i][2], rgb_values[i+1][2]],\n",
    "                'k-', alpha=0.5)\n",
    "\n",
    "    # Add arrows to show direction\n",
    "    for i in range(len(rgb_values) - 1):\n",
    "        ax.quiver(rgb_values[i][0], rgb_values[i][1], rgb_values[i][2],\n",
    "                 rgb_values[i+1][0] - rgb_values[i][0],\n",
    "                 rgb_values[i+1][1] - rgb_values[i][1],\n",
    "                 rgb_values[i+1][2] - rgb_values[i][2],\n",
    "                 color='black', arrow_length_ratio=0.1)\n",
    "\n",
    "    ax.set_xlabel('Red')\n",
    "    ax.set_ylabel('Green')\n",
    "    ax.set_zlabel('Blue')\n",
    "    ax.set_title(f'Color Trajectory: {sequence_name}')\n",
    "\n",
    "    # Add color names and matrice values as annotations\n",
    "    for i, (r, g, b) in enumerate(rgb_values):\n",
    "        ax.text(r, g, b, f'  {valid_colors[i]} ({matrice_values[i]})', size=10)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Create a second plot showing the matrice transitions\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for i in range(len(valid_colors)):\n",
    "        plt.scatter(i, 0, s=200, color=viz_colors[clusters[i]])\n",
    "        plt.text(i, 0.1, valid_colors[i], ha='center')\n",
    "        plt.text(i, -0.1, matrice_values[i], ha='center', fontweight='bold')\n",
    "\n",
    "        if i < len(valid_colors) - 1:\n",
    "            plt.arrow(i + 0.1, 0, 0.8, 0, head_width=0.05, head_length=0.1, fc='black', ec='black')\n",
    "\n",
    "    plt.ylim(-0.5, 0.5)\n",
    "    plt.xlim(-0.5, len(valid_colors) - 0.5)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Matrice Transition Sequence: {sequence_name}')\n",
    "    plt.tight_layout()\n",
    "\n",
    "# Plot trajectories for a few example sequences\n",
    "print(\"\\nPlotting color trajectories for example sequences...\")\n",
    "for _, row in sequences_df.head(3).iterrows():\n",
    "    plot_sequence_trajectory(row['ï»¿name'], row['parsed_sequence'], color_to_cluster)\n",
    "\n",
    "# Create a correlation matrix between RGB values and matrice values\n",
    "# First, create dummy variables for matrice\n",
    "matrice_dummies = pd.get_dummies(colors_df['matrice'])\n",
    "\n",
    "# Combine with RGB values\n",
    "rgb_matrice_df = pd.concat([colors_df[['r', 'g', 'b']], matrice_dummies], axis=1)\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = rgb_matrice_df.corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(corr_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.colorbar(label='Correlation')\n",
    "plt.title('Correlation between RGB Values and Matrice Values')\n",
    "plt.xticks(range(len(corr_matrix.columns)), corr_matrix.columns, rotation=90)\n",
    "plt.yticks(range(len(corr_matrix.columns)), corr_matrix.columns)\n",
    "\n",
    "# Add correlation values\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(len(corr_matrix.columns)):\n",
    "        if i < 3 and j >= 3:  # Only show RGB to matrice correlations\n",
    "            plt.text(j, i, f'{corr_matrix.iloc[i, j]:.2f}',\n",
    "                    ha='center', va='center',\n",
    "                    color='white' if abs(corr_matrix.iloc[i, j]) > 0.5 else 'black',\n",
    "                    fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "print(\"\\nAnalysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YWcDm9s-MQbn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNnewdhJMBN7"
   },
   "source": [
    "# The below code is used to input constraints and find optimal sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 43130,
     "status": "ok",
     "timestamp": 1745281591814,
     "user": {
      "displayName": "Danielle Gauthier",
      "userId": "15668431405707832125"
     },
     "user_tz": 240
    },
    "id": "L_5P4G4qUNpI",
    "outputId": "5c232971-e719-4c62-a885-90fcb5185334"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import requests\n",
    "from io import StringIO\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import silhouette_score\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "import math\n",
    "\n",
    "# Install colormath package\n",
    "!pip install colormath\n",
    "\n",
    "# Import colormath after installation\n",
    "from colormath.color_objects import sRGBColor, LabColor\n",
    "from colormath.color_conversions import convert_color\n",
    "from colormath.color_diff import delta_e_cie2000\n",
    "\n",
    "# URLs for the CSV files\n",
    "colors_url = \"https://hebbkx1anhila5yf.public.blob.vercel-storage.com/la%20matrice-qhiF8W1MZiXnmjlkL6xJasXeG1FryC.csv\"\n",
    "sequences_url = \"https://hebbkx1anhila5yf.public.blob.vercel-storage.com/la%20matrice%20sequences-2j9pbWxr7vXA22q5VUTWXYgyaSe9dO.csv\"\n",
    "semantic_mapping_url = \"https://hebbkx1anhila5yf.public.blob.vercel-storage.com/semantic_rgb_mapping-3wPDXdwfqLO8Vfft8r0P9WUC5Squqk.csv\"\n",
    "\n",
    "# Function to fetch and parse CSV data\n",
    "def fetch_csv(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return pd.read_csv(StringIO(response.text))\n",
    "    else:\n",
    "        raise Exception(f\"Failed to fetch data: {response.status_code}\")\n",
    "\n",
    "# Fetch the data\n",
    "print(\"Fetching color data...\")\n",
    "colors_df = fetch_csv(colors_url)\n",
    "print(\"Fetching sequence data...\")\n",
    "sequences_df = fetch_csv(sequences_url)\n",
    "print(\"Fetching semantic RGB mapping data...\")\n",
    "semantic_mapping_df = fetch_csv(semantic_mapping_url)\n",
    "\n",
    "# Display the first few rows of each dataset\n",
    "print(\"\\nColor Data Sample:\")\n",
    "print(colors_df.head())\n",
    "print(\"\\nSequence Data Sample:\")\n",
    "print(sequences_df.head())\n",
    "print(\"\\nSemantic RGB Mapping Sample:\")\n",
    "print(semantic_mapping_df.head())\n",
    "\n",
    "# Clean and prepare the color sentiment data\n",
    "print(\"\\nPreparing color sentiment data...\")\n",
    "\n",
    "# Make sure RGB values are numeric\n",
    "for col in ['r', 'g', 'b']:\n",
    "    colors_df[col] = pd.to_numeric(colors_df[col], errors='coerce')\n",
    "\n",
    "# Convert RGB columns to numeric in the semantic mapping\n",
    "for col in ['R', 'G', 'B']:\n",
    "    semantic_mapping_df[col] = pd.to_numeric(semantic_mapping_df[col], errors='coerce')\n",
    "\n",
    "# Extract sentiment features using text vectorization\n",
    "# First, clean the english-words column\n",
    "colors_df['clean_words'] = colors_df['english-words'].fillna('').astype(str)\n",
    "\n",
    "# Use CountVectorizer to create binary features for sentiment words\n",
    "vectorizer = CountVectorizer(binary=True, max_features=100)\n",
    "sentiment_features = vectorizer.fit_transform(colors_df['clean_words'])\n",
    "sentiment_df = pd.DataFrame(\n",
    "    sentiment_features.toarray(),\n",
    "    columns=[f'sentiment_{word}' for word in vectorizer.get_feature_names_out()],\n",
    "    index=colors_df.index\n",
    ")\n",
    "\n",
    "# Combine RGB values with sentiment features\n",
    "X_rgb = colors_df[['r', 'g', 'b']].fillna(0)\n",
    "X = pd.concat([X_rgb, sentiment_df], axis=1)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Use k=5 as specified in the original code\n",
    "k = 5\n",
    "print(f\"\\nPerforming k-means clustering with k={k}...\")\n",
    "kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "colors_df['cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Visualize the clusters using PCA for dimensionality reduction\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for cluster in range(k):\n",
    "    plt.scatter(\n",
    "        X_pca[colors_df['cluster'] == cluster, 0],\n",
    "        X_pca[colors_df['cluster'] == cluster, 1],\n",
    "        label=f'Cluster {cluster}',\n",
    "        alpha=0.7\n",
    "    )\n",
    "plt.title('Color Sentiment Clusters (PCA)')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Analyze the clusters\n",
    "print(\"\\nCluster Analysis:\")\n",
    "for cluster in range(k):\n",
    "    cluster_colors = colors_df[colors_df['cluster'] == cluster]\n",
    "    print(f\"\\nCluster {cluster} ({len(cluster_colors)} colors):\")\n",
    "    print(f\"  Common colors: {', '.join(cluster_colors['color'].value_counts().head(5).index.tolist())}\")\n",
    "\n",
    "    # Find most common sentiment words in this cluster\n",
    "    cluster_sentiments = sentiment_df.loc[cluster_colors.index].sum().sort_values(ascending=False)\n",
    "    print(f\"  Top sentiments: {', '.join(cluster_sentiments.head(5).index.str.replace('sentiment_', '').tolist())}\")\n",
    "\n",
    "    # Average RGB values for this cluster\n",
    "    avg_rgb = cluster_colors[['r', 'g', 'b']].mean()\n",
    "    print(f\"  Average RGB: ({avg_rgb['r']:.1f}, {avg_rgb['g']:.1f}, {avg_rgb['b']:.1f})\")\n",
    "\n",
    "# Create a color-to-cluster mapping\n",
    "color_to_cluster = dict(zip(colors_df['color'], colors_df['cluster']))\n",
    "\n",
    "# Parse the sequences\n",
    "print(\"\\nAnalyzing color sequences...\")\n",
    "def parse_sequence(seq_str):\n",
    "    if pd.isna(seq_str):\n",
    "        return []\n",
    "    return [color.strip().lower() for color in seq_str.split(',')]\n",
    "\n",
    "sequences_df['parsed_sequence'] = sequences_df['sequence'].apply(parse_sequence)\n",
    "\n",
    "# Calculate sequence momentum based on cluster transitions\n",
    "def calculate_momentum(sequence, color_to_cluster, cluster_weights=None):\n",
    "    if cluster_weights is None:\n",
    "        # Default weights: transitions between different clusters have higher momentum\n",
    "        cluster_weights = np.ones((k, k)) - np.eye(k)\n",
    "\n",
    "    momentum = 0\n",
    "    valid_transitions = 0\n",
    "\n",
    "    for i in range(len(sequence) - 1):\n",
    "        color1 = sequence[i]\n",
    "        color2 = sequence[i + 1]\n",
    "\n",
    "        # Skip if colors not in our dataset\n",
    "        if color1 not in color_to_cluster or color2 not in color_to_cluster:\n",
    "            continue\n",
    "\n",
    "        cluster1 = color_to_cluster[color1]\n",
    "        cluster2 = color_to_cluster[color2]\n",
    "\n",
    "        # Add momentum based on cluster transition\n",
    "        momentum += cluster_weights[cluster1, cluster2]\n",
    "        valid_transitions += 1\n",
    "\n",
    "    # Return average momentum per transition to normalize for sequence length\n",
    "    return momentum / max(1, valid_transitions)\n",
    "\n",
    "# Define cluster transition weights based on sentiment similarity\n",
    "# Calculate sentiment similarity between clusters\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "# Extract just the sentiment part of the cluster centers (not RGB)\n",
    "sentiment_centers = cluster_centers[:, 3:]\n",
    "# Calculate cosine similarity between sentiment centers\n",
    "sentiment_similarity = np.zeros((k, k))\n",
    "for i in range(k):\n",
    "    for j in range(k):\n",
    "        # Dot product of normalized vectors = cosine similarity\n",
    "        norm_i = np.linalg.norm(sentiment_centers[i])\n",
    "        norm_j = np.linalg.norm(sentiment_centers[j])\n",
    "        if norm_i > 0 and norm_j > 0:\n",
    "            sentiment_similarity[i, j] = np.dot(sentiment_centers[i], sentiment_centers[j]) / (norm_i * norm_j)\n",
    "        else:\n",
    "            sentiment_similarity[i, j] = 0\n",
    "\n",
    "# Convert similarity to weights (higher similarity = lower momentum)\n",
    "cluster_weights = 1 - sentiment_similarity\n",
    "\n",
    "# Visualize the cluster transition weights as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(cluster_weights, cmap='viridis', interpolation='nearest')\n",
    "plt.colorbar(label='Momentum Weight')\n",
    "plt.title('Cluster Transition Momentum Weights')\n",
    "plt.xlabel('To Cluster')\n",
    "plt.ylabel('From Cluster')\n",
    "for i in range(k):\n",
    "    for j in range(k):\n",
    "        plt.text(j, i, f'{cluster_weights[i, j]:.2f}',\n",
    "                 ha='center', va='center',\n",
    "                 color='white' if cluster_weights[i, j] > 0.5 else 'black')\n",
    "plt.xticks(range(k))\n",
    "plt.yticks(range(k))\n",
    "\n",
    "# Calculate momentum for each sequence\n",
    "sequences_df['momentum'] = sequences_df['parsed_sequence'].apply(\n",
    "    lambda seq: calculate_momentum(seq, color_to_cluster, cluster_weights)\n",
    ")\n",
    "\n",
    "# Find sequences with highest and lowest momentum\n",
    "print(\"\\nSequences with Highest Momentum:\")\n",
    "high_momentum = sequences_df.sort_values('momentum', ascending=False).head(5)\n",
    "for _, row in high_momentum.iterrows():\n",
    "    print(f\"  {row['ï»¿name']}: {row['sequence']} (Momentum: {row['momentum']:.2f})\")\n",
    "\n",
    "print(\"\\nSequences with Lowest Momentum:\")\n",
    "low_momentum = sequences_df.sort_values('momentum').head(5)\n",
    "for _, row in low_momentum.iterrows():\n",
    "    print(f\"  {row['ï»¿name']}: {row['sequence']} (Momentum: {row['momentum']:.2f})\")\n",
    "\n",
    "# Create a function to find the closest semantic mapping for a given RGB value\n",
    "def find_closest_semantic(r, g, b, semantic_df):\n",
    "    min_distance = float('inf')\n",
    "    closest_row = None\n",
    "\n",
    "    for _, row in semantic_df.iterrows():\n",
    "        # Calculate Euclidean distance in RGB space\n",
    "        distance = np.sqrt((r - row['R'])**2 + (g - row['G'])**2 + (b - row['B'])**2)\n",
    "\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_row = row\n",
    "\n",
    "    return closest_row\n",
    "\n",
    "# Enhance the colors_df with semantic information\n",
    "print(\"\\nEnhancing color data with semantic information...\")\n",
    "colors_df['semantic_words'] = None\n",
    "colors_df['semantic_closest_color'] = None\n",
    "\n",
    "for idx, row in colors_df.iterrows():\n",
    "    if pd.notna(row['r']) and pd.notna(row['g']) and pd.notna(row['b']):\n",
    "        closest = find_closest_semantic(row['r'], row['g'], row['b'], semantic_mapping_df)\n",
    "        if closest is not None:\n",
    "            colors_df.at[idx, 'semantic_words'] = closest['New Words'] if pd.notna(closest['New Words']) else closest['Original Words']\n",
    "            colors_df.at[idx, 'semantic_closest_color'] = closest['Closest Color']\n",
    "\n",
    "# *******************************************************************************************************************Filter colors based on the constraints: r>128, g>0, b>0\n",
    "filtered_colors = colors_df[(colors_df['r'] > 0) & (colors_df['g'] > 0) & (colors_df['b'] > 128)]\n",
    "\n",
    "print(f\"\\nFound {len(filtered_colors)} colors that meet the constraints (r>0, g>0, b>128)\")\n",
    "print(\"\\nSample of filtered colors:\")\n",
    "print(filtered_colors.head())\n",
    "\n",
    "# Check if we have enough colors for analysis\n",
    "if len(filtered_colors) < 2:\n",
    "    print(\"Not enough colors meet the criteria for analysis. Please adjust your constraints.\")\n",
    "    # Relax constraints to get more colors\n",
    "    filtered_colors = colors_df[(colors_df['r'] > 100) & (colors_df['g'] > 0) & (colors_df['b'] > 0)]\n",
    "    print(f\"Relaxed constraints to r>100: Found {len(filtered_colors)} colors\")\n",
    "\n",
    "    if len(filtered_colors) < 2:\n",
    "        # Further relax if still not enough\n",
    "        filtered_colors = colors_df[(colors_df['r'] > 0) & (colors_df['g'] > 0) & (colors_df['b'] > 0)]\n",
    "        print(f\"Further relaxed constraints to r>0: Found {len(filtered_colors)} colors\")\n",
    "\n",
    "# Function to calculate color difference using CIEDE2000\n",
    "def color_difference(rgb1, rgb2):\n",
    "    try:\n",
    "        # Convert RGB to Lab color space\n",
    "        color1_rgb = sRGBColor(rgb1[0]/255, rgb1[1]/255, rgb1[2]/255)\n",
    "        color2_rgb = sRGBColor(rgb2[0]/255, rgb2[1]/255, rgb2[2]/255)\n",
    "\n",
    "        color1_lab = convert_color(color1_rgb, LabColor)\n",
    "        color2_lab = convert_color(color2_rgb, LabColor)\n",
    "\n",
    "        # Calculate the color difference\n",
    "        delta_e = delta_e_cie2000(color1_lab, color2_lab)\n",
    "        return delta_e\n",
    "    except Exception as e:\n",
    "        # Fallback to Euclidean distance if colormath fails\n",
    "        print(f\"Warning: Using fallback color difference calculation. Error: {e}\")\n",
    "        r_diff = rgb1[0] - rgb2[0]\n",
    "        g_diff = rgb1[1] - rgb2[1]\n",
    "        b_diff = rgb1[2] - rgb2[2]\n",
    "        return math.sqrt(0.3 * (r_diff ** 2) + 0.59 * (g_diff ** 2) + 0.11 * (b_diff ** 2))\n",
    "\n",
    "# Function to convert RGB to hex color\n",
    "def rgb_to_hex(r, g, b):\n",
    "    return f'#{int(r):02x}{int(g):02x}{int(b):02x}'\n",
    "\n",
    "# Visualize the filtered colors in RGB space\n",
    "if len(filtered_colors) > 0:\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Define a list of distinct colors for visualization\n",
    "    viz_colors = ['red', 'blue', 'green', 'purple', 'orange']\n",
    "\n",
    "    for cluster in range(k):\n",
    "        cluster_colors = filtered_colors[filtered_colors['cluster'] == cluster]\n",
    "        if len(cluster_colors) > 0:\n",
    "            ax.scatter(\n",
    "                cluster_colors['r'],\n",
    "                cluster_colors['g'],\n",
    "                cluster_colors['b'],\n",
    "                color=viz_colors[cluster % len(viz_colors)],\n",
    "                label=f'Cluster {cluster}',\n",
    "                alpha=0.7\n",
    "            )\n",
    "\n",
    "    ax.set_xlabel('Red')\n",
    "    ax.set_ylabel('Green')\n",
    "    ax.set_zlabel('Blue')\n",
    "    ax.set_title('Filtered Colors in RGB Space (r>128, g>0, b>0)')\n",
    "    plt.legend()\n",
    "\n",
    "# Function to optimize a sequence by maximizing or minimizing momentum\n",
    "def optimize_sequence(sequence, color_to_cluster, cluster_weights, maximize=True, iterations=100):\n",
    "    colors_in_clusters = {}\n",
    "    for color, cluster in color_to_cluster.items():\n",
    "        if cluster not in colors_in_clusters:\n",
    "            colors_in_clusters[cluster] = []\n",
    "        colors_in_clusters[cluster].append(color)\n",
    "\n",
    "    best_sequence = sequence.copy()\n",
    "    best_momentum = calculate_momentum(best_sequence, color_to_cluster, cluster_weights)\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        # Randomly select a position to modify\n",
    "        if len(sequence) == 0:\n",
    "            continue\n",
    "        pos = np.random.randint(0, len(sequence))\n",
    "\n",
    "        # Get current color and its cluster\n",
    "        if sequence[pos] not in color_to_cluster:\n",
    "            continue\n",
    "        current_cluster = color_to_cluster[sequence[pos]]\n",
    "\n",
    "        # Choose a random different cluster and a random color from it\n",
    "        other_clusters = [c for c in range(k) if c != current_cluster and c in colors_in_clusters]\n",
    "        if not other_clusters:\n",
    "            continue\n",
    "        new_cluster = np.random.choice(other_clusters)\n",
    "        new_color = np.random.choice(colors_in_clusters[new_cluster])\n",
    "\n",
    "        # Create a new sequence with the modified color\n",
    "        new_sequence = sequence.copy()\n",
    "        new_sequence[pos] = new_color\n",
    "\n",
    "        # Calculate new momentum\n",
    "        new_momentum = calculate_momentum(new_sequence, color_to_cluster, cluster_weights)\n",
    "\n",
    "        # Update if better (higher momentum if maximizing, lower if minimizing)\n",
    "        if (maximize and new_momentum > best_momentum) or (not maximize and new_momentum < best_momentum):\n",
    "            best_sequence = new_sequence\n",
    "            best_momentum = new_momentum\n",
    "\n",
    "    return best_sequence, best_momentum\n",
    "\n",
    "# Function to optimize a sequence using both cluster transitions and semantic information\n",
    "def optimize_sequence_with_semantics(sequence, color_to_cluster, cluster_weights, colors_df, maximize=True, iterations=100):\n",
    "    \"\"\"\n",
    "    Optimize a color sequence using both cluster transitions and semantic information.\n",
    "\n",
    "    Args:\n",
    "        sequence: List of color names to optimize\n",
    "        color_to_cluster: Dictionary mapping color names to cluster IDs\n",
    "        cluster_weights: Matrix of weights for cluster transitions\n",
    "        colors_df: DataFrame containing color information including semantic data\n",
    "        maximize: Whether to maximize (True) or minimize (False) momentum\n",
    "        iterations: Number of optimization iterations\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (optimized sequence, momentum score)\n",
    "    \"\"\"\n",
    "    # Skip optimization if no valid colors or sequence\n",
    "    if len(sequence) == 0 or not color_to_cluster:\n",
    "        return sequence, 0\n",
    "\n",
    "    # Create a mapping of colors by cluster\n",
    "    colors_in_clusters = {}\n",
    "    for color, cluster in color_to_cluster.items():\n",
    "        if cluster not in colors_in_clusters:\n",
    "            colors_in_clusters[cluster] = []\n",
    "        colors_in_clusters[cluster].append(color)\n",
    "\n",
    "    # Create a mapping of colors to their semantic information\n",
    "    color_to_semantics = {}\n",
    "    for _, row in colors_df.iterrows():\n",
    "        if pd.notna(row['color']) and pd.notna(row['semantic_words']):\n",
    "            color_to_semantics[row['color']] = row['semantic_words']\n",
    "\n",
    "    best_sequence = sequence.copy()\n",
    "    best_momentum = calculate_momentum(best_sequence, color_to_cluster, cluster_weights)\n",
    "\n",
    "    # Function to calculate semantic coherence between two colors\n",
    "    def semantic_coherence(color1, color2):\n",
    "        if color1 not in color_to_semantics or color2 not in color_to_semantics:\n",
    "            return 0\n",
    "\n",
    "        # Get the semantic words for each color\n",
    "        words1 = str(color_to_semantics[color1]).lower().split(',')\n",
    "        words2 = str(color_to_semantics[color2]).lower().split(',')\n",
    "\n",
    "        # Count shared words\n",
    "        shared_words = set(words1).intersection(set(words2))\n",
    "        return len(shared_words) / max(1, (len(words1) + len(words2)) / 2)\n",
    "\n",
    "    # Calculate semantic coherence for a sequence\n",
    "    def calculate_semantic_coherence(seq):\n",
    "        coherence = 0\n",
    "        for i in range(len(seq) - 1):\n",
    "            coherence += semantic_coherence(seq[i], seq[i+1])\n",
    "        return coherence / max(1, len(seq) - 1)\n",
    "\n",
    "    # Calculate initial semantic coherence\n",
    "    best_coherence = calculate_semantic_coherence(best_sequence)\n",
    "\n",
    "    # Weight for balancing momentum vs semantic coherence\n",
    "    semantic_weight = 0.3  # Adjust this to change the importance of semantics\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        # Randomly select a position to modify\n",
    "        if len(sequence) == 0:\n",
    "            continue\n",
    "        pos = np.random.randint(0, len(sequence))\n",
    "\n",
    "        # Get current color and its cluster\n",
    "        if sequence[pos] not in color_to_cluster:\n",
    "            continue\n",
    "        current_cluster = color_to_cluster[sequence[pos]]\n",
    "\n",
    "        # Choose a random different cluster and a random color from it\n",
    "        other_clusters = [c for c in range(k) if c != current_cluster and c in colors_in_clusters]\n",
    "        if not other_clusters:\n",
    "            continue\n",
    "        new_cluster = np.random.choice(other_clusters)\n",
    "        new_color = np.random.choice(colors_in_clusters[new_cluster])\n",
    "\n",
    "        # Create a new sequence with the modified color\n",
    "        new_sequence = best_sequence.copy()\n",
    "        new_sequence[pos] = new_color\n",
    "\n",
    "        # Calculate new momentum and semantic coherence\n",
    "        new_momentum = calculate_momentum(new_sequence, color_to_cluster, cluster_weights)\n",
    "        new_coherence = calculate_semantic_coherence(new_sequence)\n",
    "\n",
    "        # Combined score (weighted sum of momentum and coherence)\n",
    "        current_score = best_momentum + semantic_weight * best_coherence\n",
    "        new_score = new_momentum + semantic_weight * new_coherence\n",
    "\n",
    "        # Update if better (higher score if maximizing, lower if minimizing)\n",
    "        if (maximize and new_score > current_score) or (not maximize and new_score < current_score):\n",
    "            best_sequence = new_sequence\n",
    "            best_momentum = new_momentum\n",
    "            best_coherence = new_coherence\n",
    "\n",
    "    return best_sequence, best_momentum\n",
    "\n",
    "# Create a function to generate new sequences based on sentiment clusters\n",
    "def generate_sequence_from_clusters(length, color_to_cluster, colors_in_clusters, target_clusters=None):\n",
    "    if target_clusters is None:\n",
    "        target_clusters = list(range(k))\n",
    "\n",
    "    sequence = []\n",
    "    for _ in range(length):\n",
    "        # Choose a cluster from target clusters\n",
    "        cluster = np.random.choice(target_clusters)\n",
    "\n",
    "        # Choose a random color from that cluster\n",
    "        if cluster in colors_in_clusters and colors_in_clusters[cluster]:\n",
    "            color = np.random.choice(colors_in_clusters[cluster])\n",
    "            sequence.append(color)\n",
    "\n",
    "    return sequence\n",
    "\n",
    "# Group colors by cluster\n",
    "colors_in_clusters = {}\n",
    "for color, cluster in color_to_cluster.items():\n",
    "    if cluster not in colors_in_clusters:\n",
    "        colors_in_clusters[cluster] = []\n",
    "    colors_in_clusters[cluster].append(color)\n",
    "\n",
    "# Function to generate a sequence based on semantic themes\n",
    "def generate_semantic_theme_sequence(colors_df, theme, length=5):\n",
    "    \"\"\"\n",
    "    Generate a color sequence based on a semantic theme.\n",
    "\n",
    "    Args:\n",
    "        colors_df: DataFrame containing color information including semantic data\n",
    "        theme: The theme word to search for in semantic words\n",
    "        length: Desired length of the sequence\n",
    "\n",
    "    Returns:\n",
    "        List of color rows that match the theme\n",
    "    \"\"\"\n",
    "    # Find colors with semantic words matching the theme\n",
    "    theme_colors = []\n",
    "    for _, row in colors_df.iterrows():\n",
    "        if pd.notna(row['semantic_words']) and theme.lower() in str(row['semantic_words']).lower():\n",
    "            theme_colors.append(row)\n",
    "\n",
    "    # If we don't have enough theme colors, add some random colors\n",
    "    if len(theme_colors) < length:\n",
    "        # Get colors not already in theme_colors\n",
    "        remaining_colors = colors_df[~colors_df['color'].isin([c['color'] for c in theme_colors])]\n",
    "        # Add random colors to reach desired length\n",
    "        if not remaining_colors.empty:\n",
    "            additional_colors = remaining_colors.sample(min(length - len(theme_colors), len(remaining_colors)))\n",
    "            theme_colors.extend(additional_colors.to_dict('records'))\n",
    "\n",
    "    # If we have more than needed, sample randomly\n",
    "    if len(theme_colors) > length:\n",
    "        theme_colors = random.sample(theme_colors, length)\n",
    "\n",
    "    return theme_colors\n",
    "\n",
    "# Function to visualize a color sequence\n",
    "def visualize_sequence(sequence, title):\n",
    "    if not sequence:\n",
    "        print(f\"No colors available for {title}\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    for i, color in enumerate(sequence):\n",
    "        plt.subplot(1, len(sequence), i + 1)\n",
    "        plt.fill([0, 1, 1, 0], [0, 0, 1, 1], color=rgb_to_hex(color['r'], color['g'], color['b']))\n",
    "        plt.axis('off')\n",
    "        plt.title(color['color'], fontsize=10)\n",
    "    plt.suptitle(title, fontsize=14)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.9])\n",
    "\n",
    "# Generate new sequences based on specific sentiment clusters\n",
    "print(\"\\nGenerating New Sequences Based on Sentiment Clusters:\")\n",
    "for cluster in range(k):\n",
    "    new_sequence = generate_sequence_from_clusters(5, color_to_cluster, colors_in_clusters, [cluster])\n",
    "    momentum = calculate_momentum(new_sequence, color_to_cluster, cluster_weights)\n",
    "    print(f\"Sequence from Cluster {cluster}: {', '.join(new_sequence)} (Momentum: {momentum:.2f})\")\n",
    "\n",
    "# Generate a sequence with maximum expected momentum\n",
    "print(\"\\nGenerating a Sequence with Maximum Expected Momentum:\")\n",
    "# Find cluster pairs with highest weights\n",
    "flat_weights = cluster_weights.flatten()\n",
    "top_indices = np.argsort(flat_weights)[-5:]  # Top 5 transitions\n",
    "top_pairs = [(idx // k, idx % k) for idx in top_indices]\n",
    "\n",
    "# Create a sequence alternating between these clusters\n",
    "high_momentum_sequence = []\n",
    "for _ in range(5):  # Generate a sequence of length 10\n",
    "    pair = top_pairs[np.random.randint(0, len(top_pairs))]\n",
    "    if pair[0] in colors_in_clusters and colors_in_clusters[pair[0]]:\n",
    "        high_momentum_sequence.append(np.random.choice(colors_in_clusters[pair[0]]))\n",
    "    if pair[1] in colors_in_clusters and colors_in_clusters[pair[1]]:\n",
    "        high_momentum_sequence.append(np.random.choice(colors_in_clusters[pair[1]]))\n",
    "\n",
    "momentum = calculate_momentum(high_momentum_sequence, color_to_cluster, cluster_weights)\n",
    "print(f\"High momentum sequence: {', '.join(high_momentum_sequence)} (Momentum: {momentum:.2f})\")\n",
    "\n",
    "# Generate sequences based on common themes\n",
    "print(\"\\nGenerating Sequences Based on Semantic Themes:\")\n",
    "themes = ['hope', 'trust', 'energy', 'calm', 'nature']\n",
    "for theme in themes:\n",
    "    theme_sequence = generate_semantic_theme_sequence(filtered_colors, theme, length=5)\n",
    "    if theme_sequence:\n",
    "        # Visualize the sequence\n",
    "        visualize_sequence(theme_sequence, f\"Sequence for Theme: '{theme}'\")\n",
    "        print(f\"\\nSequence for Theme '{theme}':\")\n",
    "        print(\", \".join([color['color'] for color in theme_sequence]))\n",
    "    else:\n",
    "        print(f\"\\nNo colors found for theme '{theme}'\")\n",
    "\n",
    "# Example: Optimize a sequence with semantics\n",
    "print(\"\\nOptimizing Sequences with Semantic Information:\")\n",
    "if len(sequences_df) > 0:\n",
    "    sample_sequence = sequences_df.iloc[0]['parsed_sequence']\n",
    "    if len(sample_sequence) > 0:\n",
    "        print(f\"Original sequence: {', '.join(sample_sequence)}\")\n",
    "\n",
    "        # Maximize momentum with semantics\n",
    "        optimized_max, max_momentum = optimize_sequence_with_semantics(\n",
    "            sample_sequence, color_to_cluster, cluster_weights, colors_df, maximize=True\n",
    "        )\n",
    "        print(f\"Optimized for maximum momentum with semantics: {', '.join(optimized_max)} (Momentum: {max_momentum:.2f})\")\n",
    "\n",
    "        # Minimize momentum with semantics\n",
    "        optimized_min, min_momentum = optimize_sequence_with_semantics(\n",
    "            sample_sequence, color_to_cluster, cluster_weights, colors_df, maximize=False\n",
    "        )\n",
    "        print(f\"Optimized for minimum momentum with semantics: {', '.join(optimized_min)} (Momentum: {min_momentum:.2f})\")\n",
    "\n",
    "# Add a visualization of semantic word frequency\n",
    "print(\"\\nAnalyzing semantic word frequency...\")\n",
    "all_words = []\n",
    "for words in filtered_colors['semantic_words'].dropna():\n",
    "    all_words.extend([w.strip().lower() for w in str(words).split(',')])\n",
    "\n",
    "word_freq = pd.Series(all_words).value_counts()\n",
    "top_words = word_freq.head(20)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_words.plot(kind='bar')\n",
    "plt.title('Top 20 Semantic Words in Filtered Colors')\n",
    "plt.xlabel('Word')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Function to generate an optimal sequence for both momentum and semantic coherence\n",
    "def generate_optimal_semantic_sequence(filtered_colors, color_to_cluster, cluster_weights, length=5, iterations=200):\n",
    "    \"\"\"\n",
    "    Generate a sequence optimized for both momentum and semantic coherence.\n",
    "\n",
    "    Args:\n",
    "        filtered_colors: DataFrame containing color information\n",
    "        color_to_cluster: Dictionary mapping color names to cluster IDs\n",
    "        cluster_weights: Matrix of weights for cluster transitions\n",
    "        length: Desired length of the sequence\n",
    "        iterations: Number of optimization iterations\n",
    "\n",
    "    Returns:\n",
    "        List of color rows forming the optimized sequence\n",
    "    \"\"\"\n",
    "    # Start with random colors that meet our constraints\n",
    "    initial_colors = filtered_colors.sample(min(length, len(filtered_colors)))\n",
    "    initial_sequence = initial_colors['color'].tolist()\n",
    "\n",
    "    # Optimize the sequence\n",
    "    optimized_sequence, _ = optimize_sequence_with_semantics(\n",
    "        initial_sequence, color_to_cluster, cluster_weights, filtered_colors, maximize=True, iterations=iterations\n",
    "    )\n",
    "\n",
    "    # Convert back to full color data\n",
    "    result = []\n",
    "    for color_name in optimized_sequence:\n",
    "        color_data = filtered_colors[filtered_colors['color'] == color_name]\n",
    "        if not color_data.empty:\n",
    "            result.append(color_data.iloc[0])\n",
    "\n",
    "    return result\n",
    "\n",
    "# Generate and visualize an optimal sequence\n",
    "print(\"\\nGenerating Optimal Sequence for Both Momentum and Semantic Coherence:\")\n",
    "optimal_sequence = generate_optimal_semantic_sequence(filtered_colors, color_to_cluster, cluster_weights)\n",
    "if optimal_sequence:\n",
    "    visualize_sequence(optimal_sequence, \"Optimal Sequence (Momentum + Semantics)\")\n",
    "    print(\"\\nOptimal Sequence:\")\n",
    "    for color in optimal_sequence:\n",
    "        semantic_info = color['semantic_words'] if pd.notna(color['semantic_words']) else \"No semantic data\"\n",
    "        print(f\"  {color['color']} - Semantics: {semantic_info}\")\n",
    "else:\n",
    "    print(\"Could not generate optimal sequence with available colors\")\n",
    "\n",
    "# Create a visualization of cluster sentiment profiles\n",
    "sentiment_words = [col.replace('sentiment_', '') for col in sentiment_df.columns]\n",
    "cluster_sentiment_profiles = np.zeros((k, len(sentiment_words)))\n",
    "\n",
    "for cluster in range(k):\n",
    "    cluster_colors = colors_df[colors_df['cluster'] == cluster]\n",
    "    cluster_sentiment_profiles[cluster] = sentiment_df.loc[cluster_colors.index].mean().values\n",
    "\n",
    "# Select top 10 most distinguishing sentiment words\n",
    "sentiment_variance = np.var(cluster_sentiment_profiles, axis=0)\n",
    "top_sentiment_indices = np.argsort(sentiment_variance)[-10:]\n",
    "top_sentiment_words = [sentiment_words[i] for i in top_sentiment_indices]\n",
    "top_sentiment_profiles = cluster_sentiment_profiles[:, top_sentiment_indices]\n",
    "\n",
    "# Plot sentiment profiles\n",
    "plt.figure(figsize=(14, 8))\n",
    "bar_width = 0.15\n",
    "index = np.arange(len(top_sentiment_words))\n",
    "\n",
    "for i in range(k):\n",
    "    plt.bar(index + i * bar_width, top_sentiment_profiles[i], bar_width,\n",
    "            label=f'Cluster {i}', color=viz_colors[i % len(viz_colors)])\n",
    "\n",
    "plt.xlabel('Sentiment Words')\n",
    "plt.ylabel('Average Presence')\n",
    "plt.title('Sentiment Profiles by Cluster')\n",
    "plt.xticks(index + bar_width * (k-1)/2, top_sentiment_words, rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Create a comprehensive color palette recommendation\n",
    "print(\"\\n\\nCOMPREHENSIVE COLOR PALETTE RECOMMENDATION\")\n",
    "print(\"===========================================\")\n",
    "print(\"Based on the constraints (r>0, g>0, b>128), here are the recommended color palettes:\")\n",
    "\n",
    "# List all available colors that meet the criteria\n",
    "print(\"\\nAll Available Colors Meeting Criteria:\")\n",
    "for _, row in filtered_colors.iterrows():\n",
    "    print(f\"{row['color']} (RGB: {row['r']}, {row['g']}, {row['b']})\")\n",
    "\n",
    "# If we have clusters, show colors by cluster\n",
    "if k > 1:\n",
    "    # Get the top representative colors from each cluster\n",
    "    top_colors_per_cluster = []\n",
    "    for cluster in range(k):\n",
    "        cluster_colors = filtered_colors[filtered_colors['cluster'] == cluster]\n",
    "        if not cluster_colors.empty:\n",
    "            # Get the colors in this cluster\n",
    "            top_colors = cluster_colors['color'].tolist()\n",
    "            top_colors_per_cluster.append((f\"Cluster {cluster}\", top_colors))\n",
    "\n",
    "    print(\"\\nColors by Cluster:\")\n",
    "    for cluster_name, colors in top_colors_per_cluster:\n",
    "        print(f\"{cluster_name}: {', '.join(colors)}\")\n",
    "\n",
    "# Recommend specific color combinations\n",
    "print(\"\\nRecommended Color Combinations:\")\n",
    "if 'contrasting_sequence' in locals() and 'contrasting_sequence':\n",
    "    print(f\"For Contrasting Designs: {', '.join([color['color'] for color in contrasting_sequence])}\")\n",
    "if 'harmonious_sequence' in locals() and 'harmonious_sequence':\n",
    "    print(f\"For Harmonious Designs: {', '.join([color['color'] for color in harmonious_sequence])}\")\n",
    "if 'diverse_sequence' in locals() and 'diverse_sequence':\n",
    "    print(f\"For Diverse Palettes: {', '.join([color['color'] for color in diverse_sequence])}\")\n",
    "if 'optimal_sequence' in locals() and 'optimal_sequence':\n",
    "    print(f\"For Semantic Coherence: {', '.join([color['color'] for color in optimal_sequence])}\")\n",
    "\n",
    "print(\"\\nAnalysis complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MaSfESpKdBwr"
   },
   "source": [
    "# Here's an interactive version of the same code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "2dfdf00eb4d44a7dbc3bb72d28a5f149",
      "734ca0a27f2a44d0b6d33705f1c322e4",
      "d645587753844540bbcfc7f29e30a9fa",
      "3b8f0b349fd747b2bd8501abd871fce2",
      "1cb0cabc31c545fa99ba891a999fde9c",
      "ed258cdda61144fb999e11759eeb4298",
      "aaef5b4ebc4e4ecab31ce30f1f7e2437",
      "2fc4c6d42a134cc486a2c3064d13b427",
      "e1ba79210bd3464b9756af463a962988",
      "7a4fa1d9feab4ba2ad719a025f571386",
      "a5672c6648564afe86c5f301c66e43f4",
      "9b1130c099f54ec2b002697695507dd1",
      "ad995f842d564060a6d0ba5d667a24a0",
      "5adb42bb85924c26a02a0efeb126f044",
      "9fbfd03eab67463aa952e1edc5389f35",
      "39ed89778b314ed4899ff726f57f7e90",
      "036a24df61154a258e62b4917ef68c85",
      "745778b11e564191bf086a1b010511b5",
      "d86900bb7a4346ff8c9627111fc9ed15",
      "5055d0b284be4ea09f16e99190400c3a",
      "b9197c7a839443a097badb3899eb84e1",
      "1db1cfd132a949b5a2deea46b5cbc79d",
      "245e0f188f484c16931af1ccbe8560c6",
      "30d0ffad968943bc9af96d4bf4484459",
      "a945ec76c98a41a7b201a1390817d45d",
      "75f8c1d3c5a64dc38c6b97011869fc6a",
      "31cc0a3717a24a76809d23909fd87fc5",
      "041c162452db40dbaa5ba82c460e2970",
      "89ed7841e9dc423c932de80e5cdb5984",
      "9b527142cb7f47dbbfbe6d02c06a47bb",
      "64874dd9e2744a2a8ec3dd9685fa961f",
      "0a7ade8244a34a3ba90cd8ca6dd50e6f",
      "24367cc5f91948b8bc745118f4e842aa",
      "757638bbf9ea4edfa371a948addfbd43",
      "59cd5b2aeb9a46bfa1ab385953d8c207",
      "8831190864164f3d92f6d50793798357",
      "d83e390b746f451882d9061d61954083",
      "d0b2d30e7dd8473d939e3412300bfc67",
      "b200c13ec80c4f00ac4f4d297a38c6fb",
      "242128dd0b47497bb33cdda166531e6a",
      "e8d74b31063143f7a6bd89029fd43a32",
      "22dfb813c38141c9b4f531af72b39f94",
      "62e0ef28859c4207a83570c200830efc",
      "fe56a1acbb2c47bf969d059898bea3ca",
      "ccf8a4fff71d4bf79df570e9c9b775b0",
      "6fe08ba66d9341298820383a9f2f9e6b",
      "77f39395a49a49dd92b6a012e03b1fd3"
     ]
    },
    "executionInfo": {
     "elapsed": 31250,
     "status": "ok",
     "timestamp": 1749232466994,
     "user": {
      "displayName": "Danielle Gauthier",
      "userId": "15668431405707832125"
     },
     "user_tz": 240
    },
    "id": "ZYszbNlK6py2",
    "outputId": "f960ca49-e1a0-4ee8-f9b4-1397c6669c2c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from io import StringIO\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import silhouette_score\n",
    "import random\n",
    "import math\n",
    "\n",
    "# Install required packages\n",
    "!pip install colormath ipywidgets matplotlib scikit-learn\n",
    "\n",
    "# Import colormath after installation\n",
    "from colormath.color_objects import sRGBColor, LabColor\n",
    "from colormath.color_conversions import convert_color\n",
    "from colormath.color_diff import delta_e_cie2000\n",
    "\n",
    "# URLs for the CSV files\n",
    "colors_url = \"https://hebbkx1anhila5yf.public.blob.vercel-storage.com/la%20matrice-qhiF8W1MZiXnmjlkL6xJasXeG1FryC.csv\"\n",
    "sequences_url = \"https://hebbkx1anhila5yf.public.blob.vercel-storage.com/la%20matrice%20sequences-2j9pbWxr7vXA22q5VUTWXYgyaSe9dO.csv\"\n",
    "semantic_mapping_url = \"https://hebbkx1anhila5yf.public.blob.vercel-storage.com/semantic_rgb_mapping-3wPDXdwfqLO8Vfft8r0P9WUC5Squqk.csv\"\n",
    "\n",
    "# Function to fetch and parse CSV data\n",
    "def fetch_csv(url):\n",
    "    print(f\"Fetching data from {url}...\")\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return pd.read_csv(StringIO(response.text))\n",
    "    else:\n",
    "        raise Exception(f\"Failed to fetch data: {response.status_code}\")\n",
    "\n",
    "# Global variables to store data\n",
    "colors_df = None\n",
    "sequences_df = None\n",
    "semantic_mapping_df = None\n",
    "k = 5  # Number of clusters to preserve\n",
    "kmeans = None\n",
    "color_to_cluster = None\n",
    "cluster_weights = None\n",
    "sentiment_df = None\n",
    "\n",
    "# Function to load all data\n",
    "def load_all_data():\n",
    "    global colors_df, sequences_df, semantic_mapping_df, kmeans, color_to_cluster, cluster_weights, sentiment_df\n",
    "\n",
    "    # Fetch the data\n",
    "    print(\"Loading all data...\")\n",
    "    colors_df = fetch_csv(colors_url)\n",
    "    sequences_df = fetch_csv(sequences_url)\n",
    "    semantic_mapping_df = fetch_csv(semantic_mapping_url)\n",
    "\n",
    "    # Make sure RGB values are numeric\n",
    "    for col in ['r', 'g', 'b']:\n",
    "        colors_df[col] = pd.to_numeric(colors_df[col], errors='coerce')\n",
    "\n",
    "    # Convert RGB columns to numeric in the semantic mapping\n",
    "    for col in ['R', 'G', 'B']:\n",
    "        semantic_mapping_df[col] = pd.to_numeric(semantic_mapping_df[col], errors='coerce')\n",
    "\n",
    "    # Extract sentiment features using text vectorization\n",
    "    # First, clean the english-words column\n",
    "    colors_df['clean_words'] = colors_df['english-words'].fillna('').astype(str)\n",
    "\n",
    "    # Use CountVectorizer to create binary features for sentiment words\n",
    "    vectorizer = CountVectorizer(binary=True, max_features=100)\n",
    "    sentiment_features = vectorizer.fit_transform(colors_df['clean_words'])\n",
    "    sentiment_df = pd.DataFrame(\n",
    "        sentiment_features.toarray(),\n",
    "        columns=[f'sentiment_{word}' for word in vectorizer.get_feature_names_out()],\n",
    "        index=colors_df.index\n",
    "    )\n",
    "\n",
    "    # Combine RGB values with sentiment features\n",
    "    X_rgb = colors_df[['r', 'g', 'b']].fillna(0)\n",
    "    X = pd.concat([X_rgb, sentiment_df], axis=1)\n",
    "\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Perform k-means clustering with k=5 as specified\n",
    "    print(f\"Performing k-means clustering with k={k}...\")\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    colors_df['cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "    # Create a color-to-cluster mapping\n",
    "    color_to_cluster = dict(zip(colors_df['color'], colors_df['cluster']))\n",
    "\n",
    "    # Define cluster transition weights based on sentiment similarity\n",
    "    # Calculate sentiment similarity between clusters\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "    # Extract just the sentiment part of the cluster centers (not RGB)\n",
    "    sentiment_centers = cluster_centers[:, 3:]\n",
    "    # Calculate cosine similarity between sentiment centers\n",
    "    sentiment_similarity = np.zeros((k, k))\n",
    "    for i in range(k):\n",
    "        for j in range(k):\n",
    "            # Dot product of normalized vectors = cosine similarity\n",
    "            norm_i = np.linalg.norm(sentiment_centers[i])\n",
    "            norm_j = np.linalg.norm(sentiment_centers[j])\n",
    "            if norm_i > 0 and norm_j > 0:\n",
    "                sentiment_similarity[i, j] = np.dot(sentiment_centers[i], sentiment_centers[j]) / (norm_i * norm_j)\n",
    "            else:\n",
    "                sentiment_similarity[i, j] = 0\n",
    "\n",
    "    # Convert similarity to weights (higher similarity = lower momentum)\n",
    "    cluster_weights = 1 - sentiment_similarity\n",
    "\n",
    "    # Enhance the colors_df with semantic information\n",
    "    print(\"Enhancing color data with semantic information...\")\n",
    "    colors_df['semantic_words'] = None\n",
    "    colors_df['semantic_closest_color'] = None\n",
    "\n",
    "    for idx, row in colors_df.iterrows():\n",
    "        if pd.notna(row['r']) and pd.notna(row['g']) and pd.notna(row['b']):\n",
    "            closest = find_closest_semantic(row['r'], row['g'], row['b'], semantic_mapping_df)\n",
    "            if closest is not None:\n",
    "                colors_df.at[idx, 'semantic_words'] = closest['New Words'] if pd.notna(closest['New Words']) else closest['Original Words']\n",
    "                colors_df.at[idx, 'semantic_closest_color'] = closest['Closest Color']\n",
    "\n",
    "    print(\"Data loading and preprocessing complete!\")\n",
    "\n",
    "# Function to find the closest semantic mapping for a given RGB value\n",
    "def find_closest_semantic(r, g, b, semantic_df):\n",
    "    min_distance = float('inf')\n",
    "    closest_row = None\n",
    "\n",
    "    for _, row in semantic_df.iterrows():\n",
    "        # Calculate Euclidean distance in RGB space\n",
    "        distance = np.sqrt((r - row['R'])**2 + (g - row['G'])**2 + (b - row['B'])**2)\n",
    "\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_row = row\n",
    "\n",
    "    return closest_row\n",
    "\n",
    "# Function to filter colors based on RGB constraints\n",
    "def filter_colors_by_rgb(r_min=0, r_max=255, g_min=0, g_max=255, b_min=0, b_max=255):\n",
    "    if colors_df is None:\n",
    "        print(\"Data not loaded. Please load data first.\")\n",
    "        return None\n",
    "\n",
    "    filtered = colors_df[\n",
    "        (colors_df['r'] >= r_min) & (colors_df['r'] <= r_max) &\n",
    "        (colors_df['g'] >= g_min) & (colors_df['g'] <= g_max) &\n",
    "        (colors_df['b'] >= b_min) & (colors_df['b'] <= b_max)\n",
    "    ]\n",
    "\n",
    "    print(f\"Found {len(filtered)} colors that meet the constraints\")\n",
    "    return filtered\n",
    "\n",
    "# Function to find colors associated with a word\n",
    "def find_colors_by_word(word, limit=10):\n",
    "    if colors_df is None:\n",
    "        print(\"Data not loaded. Please load data first.\")\n",
    "        return None\n",
    "\n",
    "    word = word.lower()\n",
    "\n",
    "    # Find colors with semantic words matching the word\n",
    "    matching_colors = []\n",
    "    for _, row in colors_df.iterrows():\n",
    "        if pd.notna(row['semantic_words']):\n",
    "            semantic_words = str(row['semantic_words']).lower()\n",
    "            if word in semantic_words or any(w.strip() == word for w in semantic_words.split(',')):\n",
    "                matching_colors.append(row)\n",
    "\n",
    "    # If we don't have enough matches, find colors with similar words\n",
    "    if len(matching_colors) < limit:\n",
    "        # Get all semantic words\n",
    "        all_semantic_words = set()\n",
    "        for words in colors_df['semantic_words'].dropna():\n",
    "            all_semantic_words.update([w.strip().lower() for w in str(words).split(',')])\n",
    "\n",
    "        # Find similar words\n",
    "        similar_words = find_similar_words(word, all_semantic_words)\n",
    "\n",
    "        # Find colors with similar semantic words\n",
    "        for _, row in colors_df.iterrows():\n",
    "            if pd.notna(row['semantic_words']) and row.name not in [c.name for c in matching_colors]:\n",
    "                semantic_words = str(row['semantic_words']).lower()\n",
    "                for similar_word in similar_words:\n",
    "                    if similar_word in semantic_words or any(w.strip() == similar_word for w in semantic_words.split(',')):\n",
    "                        matching_colors.append(row)\n",
    "                        break\n",
    "\n",
    "                if len(matching_colors) >= limit:\n",
    "                    break\n",
    "\n",
    "    return matching_colors[:limit]\n",
    "\n",
    "# Function to find similar words\n",
    "def find_similar_words(word, all_words, limit=5):\n",
    "    word = word.lower()\n",
    "\n",
    "    # Calculate similarity scores\n",
    "    word_scores = []\n",
    "    for dataset_word in all_words:\n",
    "        # Character overlap score\n",
    "        word_chars = set(word)\n",
    "        dataset_word_chars = set(dataset_word)\n",
    "        overlap_score = len(word_chars.intersection(dataset_word_chars)) / len(word_chars.union(dataset_word_chars))\n",
    "\n",
    "        # Prefix matching\n",
    "        prefix_len = 0\n",
    "        for i in range(min(len(word), len(dataset_word))):\n",
    "            if word[i] == dataset_word[i]:\n",
    "                prefix_len += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        prefix_score = prefix_len / max(len(word), len(dataset_word))\n",
    "\n",
    "        # Combined score\n",
    "        combined_score = (overlap_score * 0.6) + (prefix_score * 0.4)\n",
    "\n",
    "        word_scores.append((dataset_word, combined_score))\n",
    "\n",
    "    # Sort by score (descending)\n",
    "    word_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Return top matches\n",
    "    return [w for w, _ in word_scores[:limit]]\n",
    "\n",
    "# Function to convert RGB to hex color\n",
    "def rgb_to_hex(r, g, b):\n",
    "    return f'#{int(r):02x}{int(g):02x}{int(b):02x}'\n",
    "\n",
    "# Function to visualize colors\n",
    "def visualize_colors(colors_list, title=\"Color Visualization\"):\n",
    "    if not colors_list:\n",
    "        print(\"No colors to visualize\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    for i, color in enumerate(colors_list):\n",
    "        plt.subplot(1, len(colors_list), i + 1)\n",
    "        plt.fill([0, 1, 1, 0], [0, 0, 1, 1], color=rgb_to_hex(color['r'], color['g'], color['b']))\n",
    "        plt.axis('off')\n",
    "        plt.title(color['color'], fontsize=10)\n",
    "    plt.suptitle(title, fontsize=14)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.9])\n",
    "    plt.show()\n",
    "\n",
    "# Function to visualize clusters\n",
    "def visualize_clusters(filtered_colors):\n",
    "    if filtered_colors is None or len(filtered_colors) == 0:\n",
    "        print(\"No colors to visualize\")\n",
    "        return\n",
    "\n",
    "    # Define a list of distinct colors for visualization\n",
    "    viz_colors = ['red', 'blue', 'green', 'purple', 'orange']\n",
    "\n",
    "    # Create 3D plot\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    for cluster in range(k):\n",
    "        cluster_colors = filtered_colors[filtered_colors['cluster'] == cluster]\n",
    "        if len(cluster_colors) > 0:\n",
    "            ax.scatter(\n",
    "                cluster_colors['r'],\n",
    "                cluster_colors['g'],\n",
    "                cluster_colors['b'],\n",
    "                color=viz_colors[cluster % len(viz_colors)],\n",
    "                label=f'Cluster {cluster}',\n",
    "                alpha=0.7\n",
    "            )\n",
    "\n",
    "    ax.set_xlabel('Red')\n",
    "    ax.set_ylabel('Green')\n",
    "    ax.set_zlabel('Blue')\n",
    "    ax.set_title('Colors in RGB Space by Cluster')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Create cluster swatches\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for cluster in range(k):\n",
    "        cluster_colors = filtered_colors[filtered_colors['cluster'] == cluster]\n",
    "        if len(cluster_colors) > 0:\n",
    "            plt.subplot(k, 1, cluster + 1)\n",
    "\n",
    "            # Get cluster sentiment profile\n",
    "            cluster_sentiments = sentiment_df.loc[cluster_colors.index].sum().sort_values(ascending=False)\n",
    "            top_sentiments = cluster_sentiments.head(5).index.str.replace('sentiment_', '')\n",
    "\n",
    "            # Display color swatches\n",
    "            for i, (_, color) in enumerate(cluster_colors.iterrows()):\n",
    "                if i < 10:  # Limit to 10 colors per cluster\n",
    "                    plt.fill([i, i+0.9, i+0.9, i], [0, 0, 1, 1],\n",
    "                             color=rgb_to_hex(color['r'], color['g'], color['b']))\n",
    "                    plt.text(i+0.45, 0.5, color['color'],\n",
    "                             ha='center', va='center', rotation=90,\n",
    "                             fontsize=8, color='white' if sum([color['r'], color['g'], color['b']]) < 380 else 'black')\n",
    "\n",
    "            plt.title(f\"Cluster {cluster}: {', '.join(top_sentiments)}\")\n",
    "            plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to analyze a word and its associated colors\n",
    "def analyze_word(word, r_min=0, r_max=255, g_min=0, g_max=255, b_min=0, b_max=255):\n",
    "    if colors_df is None:\n",
    "        print(\"Data not loaded. Please load data first.\")\n",
    "        return\n",
    "\n",
    "    # Filter colors by RGB constraints\n",
    "    filtered_colors = filter_colors_by_rgb(r_min, r_max, g_min, g_max, b_min, b_max)\n",
    "\n",
    "    if filtered_colors is None or len(filtered_colors) == 0:\n",
    "        print(\"No colors match the RGB constraints. Try relaxing the constraints.\")\n",
    "        return\n",
    "\n",
    "    # Find colors associated with the word\n",
    "    word_colors = find_colors_by_word(word)\n",
    "\n",
    "    if not word_colors:\n",
    "        print(f\"No colors found for word '{word}'\")\n",
    "        return\n",
    "\n",
    "    # Filter word colors by RGB constraints\n",
    "    filtered_word_colors = [color for color in word_colors if color.name in filtered_colors.index]\n",
    "\n",
    "    print(f\"\\n===== Analysis for word '{word}' =====\")\n",
    "    print(f\"Found {len(filtered_word_colors)} colors associated with '{word}' that meet the RGB constraints\")\n",
    "\n",
    "    # Visualize the colors\n",
    "    if filtered_word_colors:\n",
    "        print(\"\\nColors associated with the word:\")\n",
    "        visualize_colors(filtered_word_colors, f\"Colors for '{word}'\")\n",
    "\n",
    "    # Analyze clusters\n",
    "    print(\"\\nCluster Analysis:\")\n",
    "    cluster_counts = {}\n",
    "    for color in filtered_word_colors:\n",
    "        cluster = color['cluster']\n",
    "        if cluster not in cluster_counts:\n",
    "            cluster_counts[cluster] = 0\n",
    "        cluster_counts[cluster] += 1\n",
    "\n",
    "    for cluster, count in cluster_counts.items():\n",
    "        cluster_colors = filtered_colors[filtered_colors['cluster'] == cluster]\n",
    "        cluster_sentiments = sentiment_df.loc[cluster_colors.index].sum().sort_values(ascending=False)\n",
    "        top_sentiments = cluster_sentiments.head(5).index.str.replace('sentiment_', '')\n",
    "\n",
    "        print(f\"Cluster {cluster}: {count} colors\")\n",
    "        print(f\"  Top sentiments: {', '.join(top_sentiments)}\")\n",
    "\n",
    "        # Average RGB values for this cluster\n",
    "        avg_rgb = cluster_colors[['r', 'g', 'b']].mean()\n",
    "        print(f\"  Average RGB: ({avg_rgb['r']:.1f}, {avg_rgb['g']:.1f}, {avg_rgb['b']:.1f})\")\n",
    "\n",
    "    # Visualize the clusters\n",
    "    visualize_clusters(filtered_colors)\n",
    "\n",
    "    # Generate a color palette recommendation\n",
    "    print(\"\\nRecommended Color Palette:\")\n",
    "\n",
    "    # Get colors from different clusters\n",
    "    palette = []\n",
    "    for cluster in range(k):\n",
    "        cluster_colors = filtered_colors[filtered_colors['cluster'] == cluster]\n",
    "        if len(cluster_colors) > 0:\n",
    "            # Try to find a color in this cluster that matches the word\n",
    "            word_match = False\n",
    "            for color in filtered_word_colors:\n",
    "                if color['cluster'] == cluster:\n",
    "                    palette.append(color)\n",
    "                    word_match = True\n",
    "                    break\n",
    "\n",
    "            # If no word match in this cluster, add a random color from the cluster\n",
    "            if not word_match and len(cluster_colors) > 0:\n",
    "                palette.append(cluster_colors.iloc[np.random.randint(0, len(cluster_colors))])\n",
    "\n",
    "    if palette:\n",
    "        visualize_colors(palette, f\"Recommended Palette for '{word}'\")\n",
    "\n",
    "        print(\"Palette Colors:\")\n",
    "        for color in palette:\n",
    "            semantic_info = color['semantic_words'] if pd.notna(color['semantic_words']) else \"No semantic data\"\n",
    "            print(f\"  {color['color']} - RGB: ({color['r']}, {color['g']}, {color['b']}) - Semantics: {semantic_info}\")\n",
    "    else:\n",
    "        print(\"Could not generate a palette with the available colors\")\n",
    "\n",
    "# Create the dashboard UI\n",
    "def create_dashboard():\n",
    "    # Load data first\n",
    "    load_all_data()\n",
    "\n",
    "    # Create widgets\n",
    "    word_input = widgets.Text(\n",
    "        value='',\n",
    "        placeholder='Enter a word (e.g., hope, energy, calm)',\n",
    "        description='Word:',\n",
    "        disabled=False\n",
    "    )\n",
    "\n",
    "    r_min_slider = widgets.IntSlider(value=0, min=0, max=255, step=1, description='R Min:')\n",
    "    r_max_slider = widgets.IntSlider(value=255, min=0, max=255, step=1, description='R Max:')\n",
    "    g_min_slider = widgets.IntSlider(value=0, min=0, max=255, step=1, description='G Min:')\n",
    "    g_max_slider = widgets.IntSlider(value=255, min=0, max=255, step=1, description='G Max:')\n",
    "    b_min_slider = widgets.IntSlider(value=0, min=0, max=255, step=1, description='B Min:')\n",
    "    b_max_slider = widgets.IntSlider(value=255, min=0, max=255, step=1, description='B Max:')\n",
    "\n",
    "    # Preset buttons for common constraints\n",
    "    preset_buttons = widgets.ToggleButtons(\n",
    "        options=['All Colors', 'Reds (R>128)', 'Greens (G>128)', 'Blues (B>128)', 'Warm Colors', 'Cool Colors'],\n",
    "        description='Presets:',\n",
    "        disabled=False,\n",
    "        button_style='',\n",
    "    )\n",
    "\n",
    "    # Analyze button\n",
    "    analyze_button = widgets.Button(\n",
    "        description='Analyze',\n",
    "        disabled=False,\n",
    "        button_style='success',\n",
    "        tooltip='Click to analyze the word and colors',\n",
    "        icon='search'\n",
    "    )\n",
    "\n",
    "    # Output area\n",
    "    output = widgets.Output()\n",
    "\n",
    "    # Function to handle preset selection\n",
    "    def on_preset_change(change):\n",
    "        if change['new'] == 'All Colors':\n",
    "            r_min_slider.value = 0\n",
    "            r_max_slider.value = 255\n",
    "            g_min_slider.value = 0\n",
    "            g_max_slider.value = 255\n",
    "            b_min_slider.value = 0\n",
    "            b_max_slider.value = 255\n",
    "        elif change['new'] == 'Reds (R>128)':\n",
    "            r_min_slider.value = 128\n",
    "            r_max_slider.value = 255\n",
    "            g_min_slider.value = 0\n",
    "            g_max_slider.value = 255\n",
    "            b_min_slider.value = 0\n",
    "            b_max_slider.value = 255\n",
    "        elif change['new'] == 'Greens (G>128)':\n",
    "            r_min_slider.value = 0\n",
    "            r_max_slider.value = 255\n",
    "            g_min_slider.value = 128\n",
    "            g_max_slider.value = 255\n",
    "            b_min_slider.value = 0\n",
    "            b_max_slider.value = 255\n",
    "        elif change['new'] == 'Blues (B>128)':\n",
    "            r_min_slider.value = 0\n",
    "            r_max_slider.value = 255\n",
    "            g_min_slider.value = 0\n",
    "            g_max_slider.value = 255\n",
    "            b_min_slider.value = 128\n",
    "            b_max_slider.value = 255\n",
    "        elif change['new'] == 'Warm Colors':\n",
    "            r_min_slider.value = 128\n",
    "            r_max_slider.value = 255\n",
    "            g_min_slider.value = 50\n",
    "            g_max_slider.value = 255\n",
    "            b_min_slider.value = 0\n",
    "            b_max_slider.value = 128\n",
    "        elif change['new'] == 'Cool Colors':\n",
    "            r_min_slider.value = 0\n",
    "            r_max_slider.value = 128\n",
    "            g_min_slider.value = 50\n",
    "            g_max_slider.value = 255\n",
    "            b_min_slider.value = 128\n",
    "            b_max_slider.value = 255\n",
    "\n",
    "    preset_buttons.observe(on_preset_change, names='value')\n",
    "\n",
    "    # Function to handle analyze button click\n",
    "    def on_analyze_button_clicked(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            word = word_input.value.strip()\n",
    "            if not word:\n",
    "                print(\"Please enter a word to analyze\")\n",
    "                return\n",
    "\n",
    "            analyze_word(\n",
    "                word,\n",
    "                r_min_slider.value, r_max_slider.value,\n",
    "                g_min_slider.value, g_max_slider.value,\n",
    "                b_min_slider.value, b_max_slider.value\n",
    "            )\n",
    "\n",
    "    analyze_button.on_click(on_analyze_button_clicked)\n",
    "\n",
    "    # Layout the widgets\n",
    "    header = widgets.HTML(value=\"<h1>Color Semantic Dashboard</h1><p>Enter a word and RGB constraints to find associated colors and clusters</p>\")\n",
    "\n",
    "    rgb_constraints = widgets.VBox([\n",
    "        widgets.HBox([r_min_slider, r_max_slider]),\n",
    "        widgets.HBox([g_min_slider, g_max_slider]),\n",
    "        widgets.HBox([b_min_slider, b_max_slider]),\n",
    "    ])\n",
    "\n",
    "    controls = widgets.VBox([\n",
    "        word_input,\n",
    "        widgets.HTML(value=\"<h3>RGB Constraints</h3>\"),\n",
    "        preset_buttons,\n",
    "        rgb_constraints,\n",
    "        analyze_button\n",
    "    ])\n",
    "\n",
    "    # Display the dashboard\n",
    "    display(header)\n",
    "    display(widgets.HBox([controls, output]))\n",
    "\n",
    "# Run the dashboard\n",
    "if __name__ == \"__main__\":\n",
    "    create_dashboard()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
